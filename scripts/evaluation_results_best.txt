EVALUATION RESULTS
==================================================
Average Representation Loss: 56.1710
Average VAE Loss: 40.9906
Average Total Loss: 97.1616
Average Perplexity: 1.88
Average Codebook Usage: 0.00%
Total Proteins Evaluated: 4679
==================================================

DETAILED RESULTS BY BATCH:
Batch 0: Loss=84.5672, Perplexity=1.68, Codebook Usage=0.00%
Batch 1: Loss=124.4587, Perplexity=2.39, Codebook Usage=0.00%
Batch 2: Loss=70.6312, Perplexity=1.65, Codebook Usage=0.00%
Batch 3: Loss=72.3508, Perplexity=1.42, Codebook Usage=0.00%
Batch 4: Loss=109.3916, Perplexity=1.80, Codebook Usage=0.00%
Batch 5: Loss=107.0944, Perplexity=1.77, Codebook Usage=0.00%
Batch 6: Loss=103.9432, Perplexity=2.00, Codebook Usage=0.00%
Batch 7: Loss=103.3933, Perplexity=1.92, Codebook Usage=0.00%
Batch 8: Loss=107.3836, Perplexity=1.85, Codebook Usage=0.00%
Batch 9: Loss=126.2376, Perplexity=2.48, Codebook Usage=0.00%
Batch 10: Loss=87.8331, Perplexity=1.80, Codebook Usage=0.00%
Batch 11: Loss=103.8410, Perplexity=2.01, Codebook Usage=0.00%
Batch 12: Loss=80.5062, Perplexity=1.74, Codebook Usage=0.00%
Batch 13: Loss=99.0412, Perplexity=2.02, Codebook Usage=0.00%
Batch 14: Loss=113.7307, Perplexity=2.25, Codebook Usage=0.00%
Batch 15: Loss=97.5104, Perplexity=1.74, Codebook Usage=0.00%
Batch 16: Loss=70.2297, Perplexity=1.82, Codebook Usage=0.00%
Batch 17: Loss=76.8183, Perplexity=1.41, Codebook Usage=0.00%
Batch 18: Loss=88.5783, Perplexity=1.52, Codebook Usage=0.00%
Batch 19: Loss=91.8029, Perplexity=1.74, Codebook Usage=0.00%
Batch 20: Loss=104.9550, Perplexity=2.19, Codebook Usage=0.00%
Batch 21: Loss=104.8589, Perplexity=1.79, Codebook Usage=0.00%
Batch 22: Loss=98.6553, Perplexity=1.97, Codebook Usage=0.00%
Batch 23: Loss=96.2165, Perplexity=1.84, Codebook Usage=0.00%
Batch 24: Loss=106.2484, Perplexity=1.85, Codebook Usage=0.00%
Batch 25: Loss=109.1617, Perplexity=1.86, Codebook Usage=0.00%
Batch 26: Loss=96.8269, Perplexity=1.88, Codebook Usage=0.00%
Batch 27: Loss=111.1522, Perplexity=2.16, Codebook Usage=0.00%
Batch 28: Loss=102.1708, Perplexity=2.06, Codebook Usage=0.00%
Batch 29: Loss=105.1095, Perplexity=2.05, Codebook Usage=0.00%
Batch 30: Loss=89.4436, Perplexity=1.44, Codebook Usage=0.00%
Batch 31: Loss=103.5033, Perplexity=1.96, Codebook Usage=0.00%
Batch 32: Loss=118.0505, Perplexity=2.30, Codebook Usage=0.00%
Batch 33: Loss=95.0100, Perplexity=2.01, Codebook Usage=0.00%
Batch 34: Loss=100.6622, Perplexity=1.91, Codebook Usage=0.00%
Batch 35: Loss=91.5973, Perplexity=1.20, Codebook Usage=0.00%
Batch 36: Loss=105.7769, Perplexity=1.68, Codebook Usage=0.00%
Batch 37: Loss=78.8984, Perplexity=1.53, Codebook Usage=0.00%
Batch 38: Loss=92.2820, Perplexity=1.97, Codebook Usage=0.00%
Batch 39: Loss=88.6461, Perplexity=1.58, Codebook Usage=0.00%
Batch 40: Loss=102.1636, Perplexity=2.00, Codebook Usage=0.00%
Batch 41: Loss=98.8579, Perplexity=1.70, Codebook Usage=0.00%
Batch 42: Loss=125.7730, Perplexity=2.42, Codebook Usage=0.00%
Batch 43: Loss=115.9468, Perplexity=2.09, Codebook Usage=0.00%
Batch 44: Loss=102.2844, Perplexity=2.16, Codebook Usage=0.00%
Batch 45: Loss=104.6536, Perplexity=2.15, Codebook Usage=0.00%
Batch 46: Loss=72.9165, Perplexity=1.51, Codebook Usage=0.00%
Batch 47: Loss=107.1270, Perplexity=1.77, Codebook Usage=0.00%
Batch 48: Loss=84.7181, Perplexity=1.15, Codebook Usage=0.00%
Batch 49: Loss=94.1285, Perplexity=1.88, Codebook Usage=0.00%
Batch 50: Loss=87.9619, Perplexity=2.03, Codebook Usage=0.00%
Batch 51: Loss=129.5704, Perplexity=2.29, Codebook Usage=0.00%
Batch 52: Loss=83.2253, Perplexity=1.99, Codebook Usage=0.00%
Batch 53: Loss=120.8054, Perplexity=2.12, Codebook Usage=0.00%
Batch 54: Loss=78.8244, Perplexity=2.12, Codebook Usage=0.00%
Batch 55: Loss=76.5185, Perplexity=1.80, Codebook Usage=0.00%
Batch 56: Loss=90.5334, Perplexity=1.43, Codebook Usage=0.00%
Batch 57: Loss=98.8205, Perplexity=2.02, Codebook Usage=0.00%
Batch 58: Loss=92.1147, Perplexity=1.78, Codebook Usage=0.00%
Batch 59: Loss=104.9390, Perplexity=2.10, Codebook Usage=0.00%
Batch 60: Loss=87.0821, Perplexity=1.53, Codebook Usage=0.00%
Batch 61: Loss=85.4677, Perplexity=1.60, Codebook Usage=0.00%
Batch 62: Loss=84.1132, Perplexity=1.64, Codebook Usage=0.00%
Batch 63: Loss=105.9531, Perplexity=1.80, Codebook Usage=0.00%
Batch 64: Loss=109.7926, Perplexity=2.04, Codebook Usage=0.00%
Batch 65: Loss=77.7244, Perplexity=1.73, Codebook Usage=0.00%
Batch 66: Loss=86.0293, Perplexity=1.81, Codebook Usage=0.00%
Batch 67: Loss=106.8712, Perplexity=1.72, Codebook Usage=0.00%
Batch 68: Loss=105.8166, Perplexity=2.18, Codebook Usage=0.00%
Batch 69: Loss=113.3437, Perplexity=2.13, Codebook Usage=0.00%
Batch 70: Loss=104.8182, Perplexity=2.00, Codebook Usage=0.00%
Batch 71: Loss=102.3541, Perplexity=2.00, Codebook Usage=0.00%
Batch 72: Loss=135.1000, Perplexity=2.25, Codebook Usage=0.00%
Batch 73: Loss=118.9271, Perplexity=2.12, Codebook Usage=0.00%
Batch 74: Loss=103.9092, Perplexity=1.95, Codebook Usage=0.00%
Batch 75: Loss=106.3244, Perplexity=2.01, Codebook Usage=0.00%
Batch 76: Loss=78.1249, Perplexity=1.67, Codebook Usage=0.00%
Batch 77: Loss=94.7586, Perplexity=2.02, Codebook Usage=0.00%
Batch 78: Loss=101.4184, Perplexity=1.69, Codebook Usage=0.00%
Batch 79: Loss=103.2252, Perplexity=1.99, Codebook Usage=0.00%
Batch 80: Loss=86.1741, Perplexity=1.69, Codebook Usage=0.00%
Batch 81: Loss=99.5484, Perplexity=2.04, Codebook Usage=0.00%
Batch 82: Loss=101.5805, Perplexity=2.26, Codebook Usage=0.00%
Batch 83: Loss=72.8696, Perplexity=1.27, Codebook Usage=0.00%
Batch 84: Loss=97.4939, Perplexity=1.75, Codebook Usage=0.00%
Batch 85: Loss=72.2141, Perplexity=1.99, Codebook Usage=0.00%
Batch 86: Loss=111.8084, Perplexity=2.09, Codebook Usage=0.00%
Batch 87: Loss=99.5074, Perplexity=1.94, Codebook Usage=0.00%
Batch 88: Loss=78.8342, Perplexity=1.47, Codebook Usage=0.00%
Batch 89: Loss=109.8244, Perplexity=2.33, Codebook Usage=0.00%
Batch 90: Loss=84.5393, Perplexity=1.75, Codebook Usage=0.00%
Batch 91: Loss=61.8542, Perplexity=1.24, Codebook Usage=0.00%
Batch 92: Loss=93.8228, Perplexity=1.79, Codebook Usage=0.00%
Batch 93: Loss=97.6164, Perplexity=1.84, Codebook Usage=0.00%
Batch 94: Loss=116.1165, Perplexity=2.12, Codebook Usage=0.00%
Batch 95: Loss=96.0855, Perplexity=1.95, Codebook Usage=0.00%
Batch 96: Loss=95.8726, Perplexity=2.16, Codebook Usage=0.00%
Batch 97: Loss=86.9721, Perplexity=1.72, Codebook Usage=0.00%
Batch 98: Loss=121.0123, Perplexity=2.24, Codebook Usage=0.00%
Batch 99: Loss=82.7306, Perplexity=1.80, Codebook Usage=0.00%
Batch 100: Loss=122.0968, Perplexity=2.40, Codebook Usage=0.00%
Batch 101: Loss=100.6721, Perplexity=1.81, Codebook Usage=0.00%
Batch 102: Loss=117.9024, Perplexity=2.34, Codebook Usage=0.00%
Batch 103: Loss=86.2122, Perplexity=1.57, Codebook Usage=0.00%
Batch 104: Loss=129.4232, Perplexity=2.32, Codebook Usage=0.00%
Batch 105: Loss=105.0457, Perplexity=1.72, Codebook Usage=0.00%
Batch 106: Loss=100.4303, Perplexity=1.80, Codebook Usage=0.00%
Batch 107: Loss=97.3391, Perplexity=1.77, Codebook Usage=0.00%
Batch 108: Loss=100.0984, Perplexity=1.68, Codebook Usage=0.00%
Batch 109: Loss=125.7453, Perplexity=2.31, Codebook Usage=0.00%
Batch 110: Loss=115.3156, Perplexity=2.25, Codebook Usage=0.00%
Batch 111: Loss=102.0356, Perplexity=1.77, Codebook Usage=0.00%
Batch 112: Loss=107.4496, Perplexity=2.16, Codebook Usage=0.00%
Batch 113: Loss=106.5219, Perplexity=1.84, Codebook Usage=0.00%
Batch 114: Loss=83.7268, Perplexity=1.61, Codebook Usage=0.00%
Batch 115: Loss=74.8727, Perplexity=1.54, Codebook Usage=0.00%
Batch 116: Loss=126.3594, Perplexity=2.64, Codebook Usage=0.00%
Batch 117: Loss=90.1747, Perplexity=2.20, Codebook Usage=0.00%
Batch 118: Loss=98.0088, Perplexity=1.78, Codebook Usage=0.00%
Batch 119: Loss=86.7005, Perplexity=1.81, Codebook Usage=0.00%
Batch 120: Loss=105.0016, Perplexity=2.28, Codebook Usage=0.00%
Batch 121: Loss=99.9671, Perplexity=1.91, Codebook Usage=0.00%
Batch 122: Loss=92.1176, Perplexity=1.90, Codebook Usage=0.00%
Batch 123: Loss=89.9715, Perplexity=1.64, Codebook Usage=0.00%
Batch 124: Loss=78.7530, Perplexity=1.56, Codebook Usage=0.00%
Batch 125: Loss=69.9441, Perplexity=1.43, Codebook Usage=0.00%
Batch 126: Loss=125.7335, Perplexity=2.47, Codebook Usage=0.00%
Batch 127: Loss=117.9803, Perplexity=2.33, Codebook Usage=0.00%
Batch 128: Loss=91.4851, Perplexity=1.74, Codebook Usage=0.00%
Batch 129: Loss=106.6873, Perplexity=2.00, Codebook Usage=0.00%
Batch 130: Loss=88.0181, Perplexity=1.89, Codebook Usage=0.00%
Batch 131: Loss=115.6387, Perplexity=2.19, Codebook Usage=0.00%
Batch 132: Loss=91.5849, Perplexity=1.63, Codebook Usage=0.00%
Batch 133: Loss=145.1411, Perplexity=2.77, Codebook Usage=0.00%
Batch 134: Loss=89.8861, Perplexity=1.68, Codebook Usage=0.00%
Batch 135: Loss=90.7122, Perplexity=1.60, Codebook Usage=0.00%
Batch 136: Loss=116.4382, Perplexity=2.17, Codebook Usage=0.00%
Batch 137: Loss=85.4796, Perplexity=1.76, Codebook Usage=0.00%
Batch 138: Loss=115.4187, Perplexity=2.08, Codebook Usage=0.00%
Batch 139: Loss=103.3626, Perplexity=1.51, Codebook Usage=0.00%
Batch 140: Loss=68.5413, Perplexity=1.68, Codebook Usage=0.00%
Batch 141: Loss=91.2467, Perplexity=1.69, Codebook Usage=0.00%
Batch 142: Loss=92.8676, Perplexity=1.79, Codebook Usage=0.00%
Batch 143: Loss=82.9628, Perplexity=1.78, Codebook Usage=0.00%
Batch 144: Loss=76.4634, Perplexity=1.81, Codebook Usage=0.00%
Batch 145: Loss=106.1509, Perplexity=2.05, Codebook Usage=0.00%
Batch 146: Loss=101.1904, Perplexity=1.85, Codebook Usage=0.00%
Batch 147: Loss=94.2981, Perplexity=1.80, Codebook Usage=0.00%
Batch 148: Loss=89.0594, Perplexity=1.69, Codebook Usage=0.00%
Batch 149: Loss=125.7260, Perplexity=2.03, Codebook Usage=0.00%
Batch 150: Loss=94.1827, Perplexity=1.73, Codebook Usage=0.00%
Batch 151: Loss=116.6229, Perplexity=2.21, Codebook Usage=0.00%
Batch 152: Loss=132.2609, Perplexity=2.65, Codebook Usage=0.00%
Batch 153: Loss=79.3583, Perplexity=1.52, Codebook Usage=0.00%
Batch 154: Loss=91.4208, Perplexity=1.58, Codebook Usage=0.00%
Batch 155: Loss=86.4173, Perplexity=1.75, Codebook Usage=0.00%
Batch 156: Loss=69.0279, Perplexity=1.81, Codebook Usage=0.00%
Batch 157: Loss=98.7634, Perplexity=1.89, Codebook Usage=0.00%
Batch 158: Loss=105.4041, Perplexity=2.10, Codebook Usage=0.00%
Batch 159: Loss=90.4711, Perplexity=1.71, Codebook Usage=0.00%
Batch 160: Loss=124.7200, Perplexity=2.33, Codebook Usage=0.00%
Batch 161: Loss=95.2077, Perplexity=1.80, Codebook Usage=0.00%
Batch 162: Loss=95.1302, Perplexity=2.05, Codebook Usage=0.00%
Batch 163: Loss=101.9919, Perplexity=1.93, Codebook Usage=0.00%
Batch 164: Loss=97.3015, Perplexity=1.81, Codebook Usage=0.00%
Batch 165: Loss=87.6828, Perplexity=1.43, Codebook Usage=0.00%
Batch 166: Loss=97.8104, Perplexity=2.09, Codebook Usage=0.00%
Batch 167: Loss=78.7337, Perplexity=1.72, Codebook Usage=0.00%
Batch 168: Loss=90.7135, Perplexity=1.45, Codebook Usage=0.00%
Batch 169: Loss=80.3721, Perplexity=1.63, Codebook Usage=0.00%
Batch 170: Loss=112.1400, Perplexity=2.17, Codebook Usage=0.00%
Batch 171: Loss=121.4326, Perplexity=2.42, Codebook Usage=0.00%
Batch 172: Loss=111.3394, Perplexity=1.90, Codebook Usage=0.00%
Batch 173: Loss=117.7131, Perplexity=2.18, Codebook Usage=0.00%
Batch 174: Loss=79.9639, Perplexity=1.59, Codebook Usage=0.00%
Batch 175: Loss=83.9909, Perplexity=1.45, Codebook Usage=0.00%
Batch 176: Loss=83.3518, Perplexity=1.82, Codebook Usage=0.00%
Batch 177: Loss=89.0747, Perplexity=1.39, Codebook Usage=0.00%
Batch 178: Loss=80.7724, Perplexity=1.49, Codebook Usage=0.00%
Batch 179: Loss=119.9643, Perplexity=2.47, Codebook Usage=0.00%
Batch 180: Loss=111.9927, Perplexity=2.14, Codebook Usage=0.00%
Batch 181: Loss=89.7736, Perplexity=1.84, Codebook Usage=0.00%
Batch 182: Loss=101.7739, Perplexity=1.77, Codebook Usage=0.00%
Batch 183: Loss=99.9343, Perplexity=2.10, Codebook Usage=0.00%
Batch 184: Loss=51.0131, Perplexity=1.29, Codebook Usage=0.00%
Batch 185: Loss=118.3535, Perplexity=2.39, Codebook Usage=0.00%
Batch 186: Loss=137.2703, Perplexity=2.53, Codebook Usage=0.00%
Batch 187: Loss=77.1526, Perplexity=1.44, Codebook Usage=0.00%
Batch 188: Loss=68.7743, Perplexity=1.66, Codebook Usage=0.00%
Batch 189: Loss=101.6844, Perplexity=1.85, Codebook Usage=0.00%
Batch 190: Loss=74.2609, Perplexity=1.50, Codebook Usage=0.00%
Batch 191: Loss=76.2808, Perplexity=2.12, Codebook Usage=0.00%
Batch 192: Loss=103.1652, Perplexity=1.94, Codebook Usage=0.00%
Batch 193: Loss=102.8467, Perplexity=1.95, Codebook Usage=0.00%
Batch 194: Loss=79.6118, Perplexity=1.77, Codebook Usage=0.00%
Batch 195: Loss=88.4651, Perplexity=2.01, Codebook Usage=0.00%
Batch 196: Loss=117.3247, Perplexity=2.07, Codebook Usage=0.00%
Batch 197: Loss=110.4326, Perplexity=1.92, Codebook Usage=0.00%
Batch 198: Loss=98.2850, Perplexity=1.60, Codebook Usage=0.00%
Batch 199: Loss=72.7198, Perplexity=1.59, Codebook Usage=0.00%
Batch 200: Loss=118.0035, Perplexity=2.20, Codebook Usage=0.00%
Batch 201: Loss=112.5829, Perplexity=2.20, Codebook Usage=0.00%
Batch 202: Loss=93.8001, Perplexity=1.72, Codebook Usage=0.00%
Batch 203: Loss=133.7213, Perplexity=2.68, Codebook Usage=0.00%
Batch 204: Loss=95.2784, Perplexity=2.02, Codebook Usage=0.00%
Batch 205: Loss=134.4639, Perplexity=2.50, Codebook Usage=0.00%
Batch 206: Loss=131.1852, Perplexity=2.59, Codebook Usage=0.00%
Batch 207: Loss=90.1670, Perplexity=1.75, Codebook Usage=0.00%
Batch 208: Loss=69.1876, Perplexity=1.45, Codebook Usage=0.00%
Batch 209: Loss=101.2701, Perplexity=2.21, Codebook Usage=0.00%
Batch 210: Loss=70.1656, Perplexity=1.62, Codebook Usage=0.00%
Batch 211: Loss=115.6246, Perplexity=2.35, Codebook Usage=0.00%
Batch 212: Loss=117.4657, Perplexity=1.88, Codebook Usage=0.00%
Batch 213: Loss=90.6919, Perplexity=1.93, Codebook Usage=0.00%
Batch 214: Loss=112.2785, Perplexity=2.20, Codebook Usage=0.00%
Batch 215: Loss=80.8333, Perplexity=1.69, Codebook Usage=0.00%
Batch 216: Loss=59.3892, Perplexity=1.59, Codebook Usage=0.00%
Batch 217: Loss=90.7769, Perplexity=1.56, Codebook Usage=0.00%
Batch 218: Loss=98.0424, Perplexity=1.78, Codebook Usage=0.00%
Batch 219: Loss=108.9650, Perplexity=1.92, Codebook Usage=0.00%
Batch 220: Loss=98.1531, Perplexity=1.71, Codebook Usage=0.00%
Batch 221: Loss=107.2825, Perplexity=1.80, Codebook Usage=0.00%
Batch 222: Loss=101.8571, Perplexity=2.01, Codebook Usage=0.00%
Batch 223: Loss=102.2758, Perplexity=1.77, Codebook Usage=0.00%
Batch 224: Loss=82.3680, Perplexity=2.13, Codebook Usage=0.00%
Batch 225: Loss=86.4157, Perplexity=1.56, Codebook Usage=0.00%
Batch 226: Loss=104.2019, Perplexity=2.12, Codebook Usage=0.00%
Batch 227: Loss=87.3578, Perplexity=1.59, Codebook Usage=0.00%
Batch 228: Loss=82.4193, Perplexity=1.78, Codebook Usage=0.00%
Batch 229: Loss=89.7529, Perplexity=1.94, Codebook Usage=0.00%
Batch 230: Loss=105.8228, Perplexity=1.97, Codebook Usage=0.00%
Batch 231: Loss=105.8349, Perplexity=1.89, Codebook Usage=0.00%
Batch 232: Loss=133.7873, Perplexity=2.49, Codebook Usage=0.00%
Batch 233: Loss=80.9425, Perplexity=1.90, Codebook Usage=0.00%
Batch 234: Loss=92.4676, Perplexity=1.89, Codebook Usage=0.00%
Batch 235: Loss=103.5957, Perplexity=1.99, Codebook Usage=0.00%
Batch 236: Loss=80.3158, Perplexity=1.91, Codebook Usage=0.00%
Batch 237: Loss=99.9820, Perplexity=1.69, Codebook Usage=0.00%
Batch 238: Loss=114.1109, Perplexity=1.81, Codebook Usage=0.00%
Batch 239: Loss=77.8877, Perplexity=1.49, Codebook Usage=0.00%
Batch 240: Loss=104.3013, Perplexity=1.95, Codebook Usage=0.00%
Batch 241: Loss=101.9184, Perplexity=1.99, Codebook Usage=0.00%
Batch 242: Loss=144.4958, Perplexity=2.60, Codebook Usage=0.00%
Batch 243: Loss=119.2901, Perplexity=2.27, Codebook Usage=0.00%
Batch 244: Loss=103.1290, Perplexity=1.99, Codebook Usage=0.00%
Batch 245: Loss=72.1328, Perplexity=1.38, Codebook Usage=0.00%
Batch 246: Loss=91.3555, Perplexity=1.74, Codebook Usage=0.00%
Batch 247: Loss=105.9359, Perplexity=2.17, Codebook Usage=0.00%
Batch 248: Loss=89.6306, Perplexity=1.79, Codebook Usage=0.00%
Batch 249: Loss=119.5808, Perplexity=2.49, Codebook Usage=0.00%
Batch 250: Loss=121.5417, Perplexity=2.18, Codebook Usage=0.00%
Batch 251: Loss=108.7604, Perplexity=2.19, Codebook Usage=0.00%
Batch 252: Loss=83.6063, Perplexity=1.91, Codebook Usage=0.00%
Batch 253: Loss=109.4638, Perplexity=1.74, Codebook Usage=0.00%
Batch 254: Loss=79.5452, Perplexity=1.72, Codebook Usage=0.00%
Batch 255: Loss=87.7803, Perplexity=1.65, Codebook Usage=0.00%
Batch 256: Loss=103.4939, Perplexity=1.94, Codebook Usage=0.00%
Batch 257: Loss=119.9674, Perplexity=2.32, Codebook Usage=0.00%
Batch 258: Loss=69.7432, Perplexity=1.22, Codebook Usage=0.00%
Batch 259: Loss=71.2078, Perplexity=1.70, Codebook Usage=0.00%
Batch 260: Loss=85.4711, Perplexity=1.39, Codebook Usage=0.00%
Batch 261: Loss=73.6662, Perplexity=1.51, Codebook Usage=0.00%
Batch 262: Loss=118.3794, Perplexity=2.02, Codebook Usage=0.00%
Batch 263: Loss=87.2516, Perplexity=1.45, Codebook Usage=0.00%
Batch 264: Loss=90.9531, Perplexity=1.70, Codebook Usage=0.00%
Batch 265: Loss=107.6147, Perplexity=1.77, Codebook Usage=0.00%
Batch 266: Loss=115.3483, Perplexity=2.27, Codebook Usage=0.00%
Batch 267: Loss=96.6605, Perplexity=2.04, Codebook Usage=0.00%
Batch 268: Loss=92.5028, Perplexity=1.82, Codebook Usage=0.00%
Batch 269: Loss=96.2417, Perplexity=2.00, Codebook Usage=0.00%
Batch 270: Loss=93.3053, Perplexity=2.27, Codebook Usage=0.00%
Batch 271: Loss=119.6458, Perplexity=2.12, Codebook Usage=0.00%
Batch 272: Loss=121.4963, Perplexity=2.01, Codebook Usage=0.00%
Batch 273: Loss=106.4543, Perplexity=1.94, Codebook Usage=0.00%
Batch 274: Loss=94.8654, Perplexity=2.01, Codebook Usage=0.00%
Batch 275: Loss=118.3255, Perplexity=2.34, Codebook Usage=0.00%
Batch 276: Loss=134.4653, Perplexity=2.42, Codebook Usage=0.00%
Batch 277: Loss=92.7390, Perplexity=1.92, Codebook Usage=0.00%
Batch 278: Loss=135.4592, Perplexity=2.65, Codebook Usage=0.00%
Batch 279: Loss=104.4338, Perplexity=2.01, Codebook Usage=0.00%
Batch 280: Loss=112.9348, Perplexity=1.89, Codebook Usage=0.00%
Batch 281: Loss=91.3728, Perplexity=1.88, Codebook Usage=0.00%
Batch 282: Loss=75.3174, Perplexity=1.40, Codebook Usage=0.00%
Batch 283: Loss=103.5577, Perplexity=1.66, Codebook Usage=0.00%
Batch 284: Loss=105.3378, Perplexity=2.02, Codebook Usage=0.00%
Batch 285: Loss=136.9840, Perplexity=2.67, Codebook Usage=0.00%
Batch 286: Loss=122.5169, Perplexity=2.19, Codebook Usage=0.00%
Batch 287: Loss=116.9002, Perplexity=2.38, Codebook Usage=0.00%
Batch 288: Loss=129.8073, Perplexity=2.70, Codebook Usage=0.00%
Batch 289: Loss=75.8305, Perplexity=1.61, Codebook Usage=0.00%
Batch 290: Loss=95.4211, Perplexity=1.80, Codebook Usage=0.00%
Batch 291: Loss=126.9394, Perplexity=2.47, Codebook Usage=0.00%
Batch 292: Loss=58.5186, Perplexity=1.58, Codebook Usage=0.00%
Batch 293: Loss=77.7553, Perplexity=1.55, Codebook Usage=0.00%
Batch 294: Loss=93.9366, Perplexity=1.88, Codebook Usage=0.00%
Batch 295: Loss=95.5420, Perplexity=2.21, Codebook Usage=0.00%
Batch 296: Loss=88.4305, Perplexity=1.54, Codebook Usage=0.00%
Batch 297: Loss=106.1687, Perplexity=1.95, Codebook Usage=0.00%
Batch 298: Loss=124.5413, Perplexity=2.68, Codebook Usage=0.00%
Batch 299: Loss=83.0851, Perplexity=1.68, Codebook Usage=0.00%
Batch 300: Loss=97.5282, Perplexity=2.09, Codebook Usage=0.00%
Batch 301: Loss=88.8709, Perplexity=1.75, Codebook Usage=0.00%
Batch 302: Loss=85.6208, Perplexity=1.62, Codebook Usage=0.00%
Batch 303: Loss=97.3151, Perplexity=1.94, Codebook Usage=0.00%
Batch 304: Loss=118.7158, Perplexity=2.25, Codebook Usage=0.00%
Batch 305: Loss=73.2836, Perplexity=1.53, Codebook Usage=0.00%
Batch 306: Loss=123.2425, Perplexity=2.38, Codebook Usage=0.00%
Batch 307: Loss=105.5233, Perplexity=1.62, Codebook Usage=0.00%
Batch 308: Loss=89.9230, Perplexity=1.93, Codebook Usage=0.00%
Batch 309: Loss=82.1828, Perplexity=1.95, Codebook Usage=0.00%
Batch 310: Loss=101.2466, Perplexity=1.87, Codebook Usage=0.00%
Batch 311: Loss=121.2640, Perplexity=2.19, Codebook Usage=0.00%
Batch 312: Loss=82.7779, Perplexity=1.70, Codebook Usage=0.00%
Batch 313: Loss=77.1305, Perplexity=1.55, Codebook Usage=0.00%
Batch 314: Loss=88.5854, Perplexity=1.71, Codebook Usage=0.00%
Batch 315: Loss=92.6892, Perplexity=1.77, Codebook Usage=0.00%
Batch 316: Loss=94.7319, Perplexity=1.78, Codebook Usage=0.00%
Batch 317: Loss=97.3305, Perplexity=2.03, Codebook Usage=0.00%
Batch 318: Loss=85.6877, Perplexity=1.65, Codebook Usage=0.00%
Batch 319: Loss=109.5271, Perplexity=2.01, Codebook Usage=0.00%
Batch 320: Loss=106.5091, Perplexity=1.84, Codebook Usage=0.00%
Batch 321: Loss=63.5744, Perplexity=1.60, Codebook Usage=0.00%
Batch 322: Loss=106.3958, Perplexity=2.06, Codebook Usage=0.00%
Batch 323: Loss=91.4783, Perplexity=1.78, Codebook Usage=0.00%
Batch 324: Loss=86.8592, Perplexity=1.85, Codebook Usage=0.00%
Batch 325: Loss=81.6300, Perplexity=1.41, Codebook Usage=0.00%
Batch 326: Loss=121.6408, Perplexity=2.18, Codebook Usage=0.00%
Batch 327: Loss=101.9749, Perplexity=2.16, Codebook Usage=0.00%
Batch 328: Loss=106.8879, Perplexity=1.77, Codebook Usage=0.00%
Batch 329: Loss=105.5645, Perplexity=1.84, Codebook Usage=0.00%
Batch 330: Loss=82.6284, Perplexity=1.55, Codebook Usage=0.00%
Batch 331: Loss=92.8616, Perplexity=1.84, Codebook Usage=0.00%
Batch 332: Loss=104.2270, Perplexity=1.93, Codebook Usage=0.00%
Batch 333: Loss=99.5210, Perplexity=2.24, Codebook Usage=0.00%
Batch 334: Loss=84.3249, Perplexity=1.49, Codebook Usage=0.00%
Batch 335: Loss=73.0617, Perplexity=1.40, Codebook Usage=0.00%
Batch 336: Loss=83.8338, Perplexity=1.98, Codebook Usage=0.00%
Batch 337: Loss=81.5804, Perplexity=2.09, Codebook Usage=0.00%
Batch 338: Loss=123.4321, Perplexity=2.48, Codebook Usage=0.00%
Batch 339: Loss=105.7413, Perplexity=1.77, Codebook Usage=0.00%
Batch 340: Loss=88.4444, Perplexity=1.70, Codebook Usage=0.00%
Batch 341: Loss=120.6518, Perplexity=2.11, Codebook Usage=0.00%
Batch 342: Loss=116.6399, Perplexity=2.32, Codebook Usage=0.00%
Batch 343: Loss=112.0218, Perplexity=2.06, Codebook Usage=0.00%
Batch 344: Loss=53.9527, Perplexity=1.54, Codebook Usage=0.00%
Batch 345: Loss=93.9826, Perplexity=2.06, Codebook Usage=0.00%
Batch 346: Loss=110.9505, Perplexity=2.18, Codebook Usage=0.00%
Batch 347: Loss=102.0041, Perplexity=2.42, Codebook Usage=0.00%
Batch 348: Loss=105.6223, Perplexity=2.20, Codebook Usage=0.00%
Batch 349: Loss=112.6683, Perplexity=2.03, Codebook Usage=0.00%
Batch 350: Loss=102.7792, Perplexity=2.32, Codebook Usage=0.00%
Batch 351: Loss=124.7921, Perplexity=2.29, Codebook Usage=0.00%
Batch 352: Loss=115.5080, Perplexity=1.87, Codebook Usage=0.00%
Batch 353: Loss=84.1932, Perplexity=1.83, Codebook Usage=0.00%
Batch 354: Loss=78.3722, Perplexity=1.60, Codebook Usage=0.00%
Batch 355: Loss=110.4451, Perplexity=1.95, Codebook Usage=0.00%
Batch 356: Loss=91.1786, Perplexity=1.43, Codebook Usage=0.00%
Batch 357: Loss=92.4550, Perplexity=1.76, Codebook Usage=0.00%
Batch 358: Loss=84.0832, Perplexity=1.60, Codebook Usage=0.00%
Batch 359: Loss=111.0600, Perplexity=2.12, Codebook Usage=0.00%
Batch 360: Loss=68.3726, Perplexity=1.54, Codebook Usage=0.00%
Batch 361: Loss=97.8619, Perplexity=1.85, Codebook Usage=0.00%
Batch 362: Loss=109.2179, Perplexity=1.86, Codebook Usage=0.00%
Batch 363: Loss=128.2040, Perplexity=2.22, Codebook Usage=0.00%
Batch 364: Loss=70.5663, Perplexity=1.52, Codebook Usage=0.00%
Batch 365: Loss=92.8178, Perplexity=1.73, Codebook Usage=0.00%
Batch 366: Loss=87.1884, Perplexity=1.47, Codebook Usage=0.00%
Batch 367: Loss=129.2544, Perplexity=2.62, Codebook Usage=0.00%
Batch 368: Loss=86.9321, Perplexity=1.69, Codebook Usage=0.00%
Batch 369: Loss=90.1596, Perplexity=1.48, Codebook Usage=0.00%
Batch 370: Loss=74.3750, Perplexity=1.89, Codebook Usage=0.00%
Batch 371: Loss=67.4576, Perplexity=1.59, Codebook Usage=0.00%
Batch 372: Loss=109.8850, Perplexity=2.16, Codebook Usage=0.00%
Batch 373: Loss=97.6828, Perplexity=1.98, Codebook Usage=0.00%
Batch 374: Loss=102.0957, Perplexity=2.30, Codebook Usage=0.00%
Batch 375: Loss=112.9917, Perplexity=2.07, Codebook Usage=0.00%
Batch 376: Loss=95.1936, Perplexity=2.08, Codebook Usage=0.00%
Batch 377: Loss=105.2256, Perplexity=1.86, Codebook Usage=0.00%
Batch 378: Loss=101.4887, Perplexity=2.22, Codebook Usage=0.00%
Batch 379: Loss=106.5978, Perplexity=1.90, Codebook Usage=0.00%
Batch 380: Loss=105.2965, Perplexity=2.17, Codebook Usage=0.00%
Batch 381: Loss=121.0654, Perplexity=2.46, Codebook Usage=0.00%
Batch 382: Loss=62.0842, Perplexity=1.37, Codebook Usage=0.00%
Batch 383: Loss=87.4084, Perplexity=1.50, Codebook Usage=0.00%
Batch 384: Loss=120.9704, Perplexity=1.98, Codebook Usage=0.00%
Batch 385: Loss=77.1129, Perplexity=1.53, Codebook Usage=0.00%
Batch 386: Loss=118.7267, Perplexity=2.28, Codebook Usage=0.00%
Batch 387: Loss=113.7626, Perplexity=2.15, Codebook Usage=0.00%
Batch 388: Loss=71.3470, Perplexity=1.58, Codebook Usage=0.00%
Batch 389: Loss=83.3745, Perplexity=1.43, Codebook Usage=0.00%
Batch 390: Loss=97.4505, Perplexity=1.97, Codebook Usage=0.00%
Batch 391: Loss=97.9180, Perplexity=2.03, Codebook Usage=0.00%
Batch 392: Loss=95.7286, Perplexity=1.96, Codebook Usage=0.00%
Batch 393: Loss=111.3265, Perplexity=1.79, Codebook Usage=0.00%
Batch 394: Loss=85.5547, Perplexity=1.95, Codebook Usage=0.00%
Batch 395: Loss=99.9718, Perplexity=1.94, Codebook Usage=0.00%
Batch 396: Loss=71.8887, Perplexity=1.71, Codebook Usage=0.00%
Batch 397: Loss=102.1594, Perplexity=1.87, Codebook Usage=0.00%
Batch 398: Loss=100.4737, Perplexity=2.07, Codebook Usage=0.00%
Batch 399: Loss=109.8436, Perplexity=1.98, Codebook Usage=0.00%
Batch 400: Loss=110.4351, Perplexity=1.64, Codebook Usage=0.00%
Batch 401: Loss=82.9914, Perplexity=1.71, Codebook Usage=0.00%
Batch 402: Loss=74.2371, Perplexity=1.54, Codebook Usage=0.00%
Batch 403: Loss=94.9153, Perplexity=1.64, Codebook Usage=0.00%
Batch 404: Loss=108.0257, Perplexity=2.15, Codebook Usage=0.00%
Batch 405: Loss=98.1276, Perplexity=1.69, Codebook Usage=0.00%
Batch 406: Loss=77.2613, Perplexity=1.22, Codebook Usage=0.00%
Batch 407: Loss=107.7821, Perplexity=2.06, Codebook Usage=0.00%
Batch 408: Loss=105.5166, Perplexity=1.88, Codebook Usage=0.00%
Batch 409: Loss=118.9117, Perplexity=2.33, Codebook Usage=0.00%
Batch 410: Loss=100.1384, Perplexity=2.15, Codebook Usage=0.00%
Batch 411: Loss=76.6734, Perplexity=1.56, Codebook Usage=0.00%
Batch 412: Loss=76.5040, Perplexity=1.80, Codebook Usage=0.00%
Batch 413: Loss=95.6145, Perplexity=1.74, Codebook Usage=0.00%
Batch 414: Loss=90.2496, Perplexity=1.56, Codebook Usage=0.00%
Batch 415: Loss=106.8215, Perplexity=1.96, Codebook Usage=0.00%
Batch 416: Loss=97.6613, Perplexity=1.98, Codebook Usage=0.00%
Batch 417: Loss=83.7918, Perplexity=1.71, Codebook Usage=0.00%
Batch 418: Loss=91.3709, Perplexity=1.83, Codebook Usage=0.00%
Batch 419: Loss=94.2429, Perplexity=1.43, Codebook Usage=0.00%
Batch 420: Loss=54.5043, Perplexity=1.44, Codebook Usage=0.00%
Batch 421: Loss=76.6547, Perplexity=1.62, Codebook Usage=0.00%
Batch 422: Loss=66.7817, Perplexity=1.71, Codebook Usage=0.00%
Batch 423: Loss=94.0809, Perplexity=1.79, Codebook Usage=0.00%
Batch 424: Loss=93.1483, Perplexity=1.86, Codebook Usage=0.00%
Batch 425: Loss=111.2284, Perplexity=2.29, Codebook Usage=0.00%
Batch 426: Loss=120.2266, Perplexity=2.22, Codebook Usage=0.00%
Batch 427: Loss=110.6701, Perplexity=1.94, Codebook Usage=0.00%
Batch 428: Loss=94.1357, Perplexity=1.76, Codebook Usage=0.00%
Batch 429: Loss=110.8033, Perplexity=2.50, Codebook Usage=0.00%
Batch 430: Loss=102.7189, Perplexity=1.94, Codebook Usage=0.00%
Batch 431: Loss=102.4633, Perplexity=1.76, Codebook Usage=0.00%
Batch 432: Loss=101.8843, Perplexity=2.03, Codebook Usage=0.00%
Batch 433: Loss=123.3604, Perplexity=2.50, Codebook Usage=0.00%
Batch 434: Loss=92.9474, Perplexity=1.66, Codebook Usage=0.00%
Batch 435: Loss=103.0570, Perplexity=1.86, Codebook Usage=0.00%
Batch 436: Loss=105.6875, Perplexity=1.85, Codebook Usage=0.00%
Batch 437: Loss=109.9035, Perplexity=2.17, Codebook Usage=0.00%
Batch 438: Loss=96.5514, Perplexity=1.81, Codebook Usage=0.00%
Batch 439: Loss=124.0104, Perplexity=2.38, Codebook Usage=0.00%
Batch 440: Loss=93.4795, Perplexity=1.93, Codebook Usage=0.00%
Batch 441: Loss=107.2000, Perplexity=1.79, Codebook Usage=0.00%
Batch 442: Loss=100.2644, Perplexity=1.77, Codebook Usage=0.00%
Batch 443: Loss=108.6684, Perplexity=2.16, Codebook Usage=0.00%
Batch 444: Loss=97.8734, Perplexity=2.09, Codebook Usage=0.00%
Batch 445: Loss=111.5570, Perplexity=2.23, Codebook Usage=0.00%
Batch 446: Loss=108.2765, Perplexity=2.31, Codebook Usage=0.00%
Batch 447: Loss=102.1154, Perplexity=2.07, Codebook Usage=0.00%
Batch 448: Loss=102.2922, Perplexity=1.93, Codebook Usage=0.00%
Batch 449: Loss=125.8956, Perplexity=2.32, Codebook Usage=0.00%
Batch 450: Loss=102.2710, Perplexity=2.05, Codebook Usage=0.00%
Batch 451: Loss=82.4221, Perplexity=1.50, Codebook Usage=0.00%
Batch 452: Loss=70.9501, Perplexity=1.54, Codebook Usage=0.00%
Batch 453: Loss=82.1254, Perplexity=1.94, Codebook Usage=0.00%
Batch 454: Loss=86.0723, Perplexity=1.68, Codebook Usage=0.00%
Batch 455: Loss=121.1875, Perplexity=2.07, Codebook Usage=0.00%
Batch 456: Loss=113.4311, Perplexity=1.74, Codebook Usage=0.00%
Batch 457: Loss=93.1349, Perplexity=2.08, Codebook Usage=0.00%
Batch 458: Loss=107.3936, Perplexity=2.03, Codebook Usage=0.00%
Batch 459: Loss=90.6821, Perplexity=1.47, Codebook Usage=0.00%
Batch 460: Loss=104.3268, Perplexity=1.79, Codebook Usage=0.00%
Batch 461: Loss=111.8520, Perplexity=2.16, Codebook Usage=0.00%
Batch 462: Loss=100.2012, Perplexity=2.05, Codebook Usage=0.00%
Batch 463: Loss=86.0488, Perplexity=2.28, Codebook Usage=0.00%
Batch 464: Loss=113.3904, Perplexity=2.15, Codebook Usage=0.00%
Batch 465: Loss=111.8183, Perplexity=2.03, Codebook Usage=0.00%
Batch 466: Loss=90.6838, Perplexity=1.47, Codebook Usage=0.00%
Batch 467: Loss=95.0817, Perplexity=1.53, Codebook Usage=0.00%
Batch 468: Loss=92.0236, Perplexity=1.53, Codebook Usage=0.00%
Batch 469: Loss=108.2670, Perplexity=2.01, Codebook Usage=0.00%
Batch 470: Loss=104.3851, Perplexity=2.07, Codebook Usage=0.00%
Batch 471: Loss=98.5925, Perplexity=1.95, Codebook Usage=0.00%
Batch 472: Loss=117.4601, Perplexity=2.15, Codebook Usage=0.00%
Batch 473: Loss=117.9324, Perplexity=1.98, Codebook Usage=0.00%
Batch 474: Loss=97.2727, Perplexity=1.76, Codebook Usage=0.00%
Batch 475: Loss=67.2002, Perplexity=1.43, Codebook Usage=0.00%
Batch 476: Loss=73.3742, Perplexity=1.81, Codebook Usage=0.00%
Batch 477: Loss=104.1442, Perplexity=2.07, Codebook Usage=0.00%
Batch 478: Loss=94.1602, Perplexity=1.74, Codebook Usage=0.00%
Batch 479: Loss=61.5425, Perplexity=1.60, Codebook Usage=0.00%
Batch 480: Loss=95.8804, Perplexity=1.85, Codebook Usage=0.00%
Batch 481: Loss=127.2185, Perplexity=2.16, Codebook Usage=0.00%
Batch 482: Loss=98.1846, Perplexity=1.96, Codebook Usage=0.00%
Batch 483: Loss=118.4688, Perplexity=2.01, Codebook Usage=0.00%
Batch 484: Loss=88.3395, Perplexity=1.97, Codebook Usage=0.00%
Batch 485: Loss=118.8140, Perplexity=2.15, Codebook Usage=0.00%
Batch 486: Loss=106.3957, Perplexity=1.75, Codebook Usage=0.00%
Batch 487: Loss=93.4106, Perplexity=2.13, Codebook Usage=0.00%
Batch 488: Loss=78.8487, Perplexity=1.66, Codebook Usage=0.00%
Batch 489: Loss=101.0626, Perplexity=2.12, Codebook Usage=0.00%
Batch 490: Loss=75.9519, Perplexity=1.57, Codebook Usage=0.00%
Batch 491: Loss=136.6231, Perplexity=2.33, Codebook Usage=0.00%
Batch 492: Loss=103.2126, Perplexity=1.58, Codebook Usage=0.00%
Batch 493: Loss=89.8694, Perplexity=1.84, Codebook Usage=0.00%
Batch 494: Loss=70.9265, Perplexity=1.55, Codebook Usage=0.00%
Batch 495: Loss=91.4893, Perplexity=1.97, Codebook Usage=0.00%
Batch 496: Loss=92.2030, Perplexity=1.70, Codebook Usage=0.00%
Batch 497: Loss=67.7803, Perplexity=1.31, Codebook Usage=0.00%
Batch 498: Loss=75.3639, Perplexity=1.53, Codebook Usage=0.00%
Batch 499: Loss=88.1424, Perplexity=1.47, Codebook Usage=0.00%
Batch 500: Loss=85.8625, Perplexity=1.96, Codebook Usage=0.00%
Batch 501: Loss=103.9896, Perplexity=2.04, Codebook Usage=0.00%
Batch 502: Loss=120.4630, Perplexity=2.10, Codebook Usage=0.00%
Batch 503: Loss=77.2026, Perplexity=1.82, Codebook Usage=0.00%
Batch 504: Loss=98.3858, Perplexity=1.50, Codebook Usage=0.00%
Batch 505: Loss=88.1796, Perplexity=1.82, Codebook Usage=0.00%
Batch 506: Loss=89.1953, Perplexity=1.98, Codebook Usage=0.00%
Batch 507: Loss=86.1058, Perplexity=1.73, Codebook Usage=0.00%
Batch 508: Loss=97.4226, Perplexity=1.84, Codebook Usage=0.00%
Batch 509: Loss=55.5928, Perplexity=1.33, Codebook Usage=0.00%
Batch 510: Loss=97.7193, Perplexity=2.26, Codebook Usage=0.00%
Batch 511: Loss=79.3253, Perplexity=1.43, Codebook Usage=0.00%
Batch 512: Loss=99.5513, Perplexity=1.87, Codebook Usage=0.00%
Batch 513: Loss=98.1201, Perplexity=2.08, Codebook Usage=0.00%
Batch 514: Loss=88.5846, Perplexity=1.71, Codebook Usage=0.00%
Batch 515: Loss=139.2328, Perplexity=2.52, Codebook Usage=0.00%
Batch 516: Loss=114.9756, Perplexity=1.75, Codebook Usage=0.00%
Batch 517: Loss=81.6471, Perplexity=1.62, Codebook Usage=0.00%
Batch 518: Loss=66.5871, Perplexity=1.53, Codebook Usage=0.00%
Batch 519: Loss=104.1143, Perplexity=2.21, Codebook Usage=0.00%
Batch 520: Loss=84.9922, Perplexity=1.67, Codebook Usage=0.00%
Batch 521: Loss=90.5187, Perplexity=1.67, Codebook Usage=0.00%
Batch 522: Loss=70.5624, Perplexity=1.64, Codebook Usage=0.00%
Batch 523: Loss=88.1568, Perplexity=1.52, Codebook Usage=0.00%
Batch 524: Loss=114.0617, Perplexity=2.01, Codebook Usage=0.00%
Batch 525: Loss=105.9906, Perplexity=1.84, Codebook Usage=0.00%
Batch 526: Loss=86.8163, Perplexity=1.61, Codebook Usage=0.00%
Batch 527: Loss=116.5162, Perplexity=2.17, Codebook Usage=0.00%
Batch 528: Loss=123.3916, Perplexity=2.07, Codebook Usage=0.00%
Batch 529: Loss=80.8150, Perplexity=1.90, Codebook Usage=0.00%
Batch 530: Loss=84.1381, Perplexity=1.66, Codebook Usage=0.00%
Batch 531: Loss=101.7032, Perplexity=2.09, Codebook Usage=0.00%
Batch 532: Loss=113.3452, Perplexity=2.16, Codebook Usage=0.00%
Batch 533: Loss=88.1463, Perplexity=1.68, Codebook Usage=0.00%
Batch 534: Loss=110.0410, Perplexity=2.41, Codebook Usage=0.00%
Batch 535: Loss=83.3853, Perplexity=1.66, Codebook Usage=0.00%
Batch 536: Loss=96.7751, Perplexity=2.01, Codebook Usage=0.00%
Batch 537: Loss=84.0763, Perplexity=1.88, Codebook Usage=0.00%
Batch 538: Loss=89.1393, Perplexity=1.56, Codebook Usage=0.00%
Batch 539: Loss=100.0521, Perplexity=1.92, Codebook Usage=0.00%
Batch 540: Loss=89.2917, Perplexity=1.63, Codebook Usage=0.00%
Batch 541: Loss=78.7735, Perplexity=1.45, Codebook Usage=0.00%
Batch 542: Loss=74.8779, Perplexity=1.55, Codebook Usage=0.00%
Batch 543: Loss=92.9241, Perplexity=2.10, Codebook Usage=0.00%
Batch 544: Loss=157.1541, Perplexity=2.79, Codebook Usage=0.00%
Batch 545: Loss=94.9763, Perplexity=1.73, Codebook Usage=0.00%
Batch 546: Loss=135.4705, Perplexity=2.58, Codebook Usage=0.00%
Batch 547: Loss=114.1071, Perplexity=2.32, Codebook Usage=0.00%
Batch 548: Loss=79.7642, Perplexity=1.70, Codebook Usage=0.00%
Batch 549: Loss=102.6966, Perplexity=1.63, Codebook Usage=0.00%
Batch 550: Loss=101.9855, Perplexity=2.07, Codebook Usage=0.00%
Batch 551: Loss=101.5196, Perplexity=1.90, Codebook Usage=0.00%
Batch 552: Loss=102.4413, Perplexity=2.04, Codebook Usage=0.00%
Batch 553: Loss=98.6471, Perplexity=1.88, Codebook Usage=0.00%
Batch 554: Loss=119.4893, Perplexity=2.31, Codebook Usage=0.00%
Batch 555: Loss=96.0605, Perplexity=1.74, Codebook Usage=0.00%
Batch 556: Loss=107.6014, Perplexity=1.98, Codebook Usage=0.00%
Batch 557: Loss=92.2385, Perplexity=1.91, Codebook Usage=0.00%
Batch 558: Loss=99.7627, Perplexity=1.63, Codebook Usage=0.00%
Batch 559: Loss=87.4335, Perplexity=1.67, Codebook Usage=0.00%
Batch 560: Loss=86.8043, Perplexity=1.91, Codebook Usage=0.00%
Batch 561: Loss=80.5965, Perplexity=1.67, Codebook Usage=0.00%
Batch 562: Loss=94.4316, Perplexity=1.97, Codebook Usage=0.00%
Batch 563: Loss=98.0430, Perplexity=1.64, Codebook Usage=0.00%
Batch 564: Loss=85.5696, Perplexity=1.57, Codebook Usage=0.00%
Batch 565: Loss=86.2806, Perplexity=1.50, Codebook Usage=0.00%
Batch 566: Loss=103.1611, Perplexity=2.02, Codebook Usage=0.00%
Batch 567: Loss=95.5910, Perplexity=1.74, Codebook Usage=0.00%
Batch 568: Loss=88.2155, Perplexity=1.73, Codebook Usage=0.00%
Batch 569: Loss=92.9990, Perplexity=1.85, Codebook Usage=0.00%
Batch 570: Loss=77.7543, Perplexity=1.88, Codebook Usage=0.00%
Batch 571: Loss=80.2177, Perplexity=1.78, Codebook Usage=0.00%
Batch 572: Loss=94.3228, Perplexity=1.61, Codebook Usage=0.00%
Batch 573: Loss=78.5898, Perplexity=1.69, Codebook Usage=0.00%
Batch 574: Loss=101.8260, Perplexity=1.86, Codebook Usage=0.00%
Batch 575: Loss=70.4744, Perplexity=1.86, Codebook Usage=0.00%
Batch 576: Loss=95.4916, Perplexity=2.10, Codebook Usage=0.00%
Batch 577: Loss=131.3911, Perplexity=2.20, Codebook Usage=0.00%
Batch 578: Loss=102.0061, Perplexity=1.73, Codebook Usage=0.00%
Batch 579: Loss=114.4804, Perplexity=2.06, Codebook Usage=0.00%
Batch 580: Loss=89.9441, Perplexity=1.48, Codebook Usage=0.00%
Batch 581: Loss=101.8723, Perplexity=2.11, Codebook Usage=0.00%
Batch 582: Loss=99.7298, Perplexity=2.01, Codebook Usage=0.00%
Batch 583: Loss=86.1940, Perplexity=1.40, Codebook Usage=0.00%
Batch 584: Loss=137.3470, Perplexity=2.67, Codebook Usage=0.00%
Batch 585: Loss=95.6841, Perplexity=1.83, Codebook Usage=0.00%
Batch 586: Loss=75.7922, Perplexity=1.51, Codebook Usage=0.00%
Batch 587: Loss=81.2313, Perplexity=1.69, Codebook Usage=0.00%
Batch 588: Loss=97.0693, Perplexity=1.92, Codebook Usage=0.00%
Batch 589: Loss=71.5091, Perplexity=1.83, Codebook Usage=0.00%
Batch 590: Loss=90.6174, Perplexity=1.64, Codebook Usage=0.00%
Batch 591: Loss=86.9940, Perplexity=1.73, Codebook Usage=0.00%
Batch 592: Loss=62.7618, Perplexity=1.66, Codebook Usage=0.00%
Batch 593: Loss=105.3331, Perplexity=2.10, Codebook Usage=0.00%
Batch 594: Loss=96.1654, Perplexity=1.80, Codebook Usage=0.00%
Batch 595: Loss=98.9381, Perplexity=1.75, Codebook Usage=0.00%
Batch 596: Loss=98.6792, Perplexity=1.67, Codebook Usage=0.00%
Batch 597: Loss=93.1514, Perplexity=1.59, Codebook Usage=0.00%
Batch 598: Loss=62.6909, Perplexity=1.53, Codebook Usage=0.00%
Batch 599: Loss=89.9618, Perplexity=1.89, Codebook Usage=0.00%
Batch 600: Loss=71.1561, Perplexity=1.87, Codebook Usage=0.00%
Batch 601: Loss=93.0900, Perplexity=1.76, Codebook Usage=0.00%
Batch 602: Loss=75.6993, Perplexity=1.75, Codebook Usage=0.00%
Batch 603: Loss=94.5124, Perplexity=1.82, Codebook Usage=0.00%
Batch 604: Loss=113.9274, Perplexity=2.00, Codebook Usage=0.00%
Batch 605: Loss=69.3327, Perplexity=1.47, Codebook Usage=0.00%
Batch 606: Loss=65.7032, Perplexity=1.53, Codebook Usage=0.00%
Batch 607: Loss=88.0161, Perplexity=1.91, Codebook Usage=0.00%
Batch 608: Loss=87.4484, Perplexity=1.59, Codebook Usage=0.00%
Batch 609: Loss=97.7836, Perplexity=1.97, Codebook Usage=0.00%
Batch 610: Loss=63.6940, Perplexity=1.75, Codebook Usage=0.00%
Batch 611: Loss=108.0900, Perplexity=1.96, Codebook Usage=0.00%
Batch 612: Loss=104.5488, Perplexity=2.18, Codebook Usage=0.00%
Batch 613: Loss=132.0641, Perplexity=2.41, Codebook Usage=0.00%
Batch 614: Loss=82.2930, Perplexity=1.80, Codebook Usage=0.00%
Batch 615: Loss=104.9199, Perplexity=1.75, Codebook Usage=0.00%
Batch 616: Loss=103.7734, Perplexity=1.93, Codebook Usage=0.00%
Batch 617: Loss=110.0160, Perplexity=1.94, Codebook Usage=0.00%
Batch 618: Loss=79.6213, Perplexity=1.89, Codebook Usage=0.00%
Batch 619: Loss=110.8934, Perplexity=1.98, Codebook Usage=0.00%
Batch 620: Loss=99.9458, Perplexity=2.06, Codebook Usage=0.00%
Batch 621: Loss=61.0329, Perplexity=1.53, Codebook Usage=0.00%
Batch 622: Loss=104.0240, Perplexity=1.69, Codebook Usage=0.00%
Batch 623: Loss=107.7866, Perplexity=1.94, Codebook Usage=0.00%
Batch 624: Loss=104.1197, Perplexity=2.03, Codebook Usage=0.00%
Batch 625: Loss=76.5762, Perplexity=1.61, Codebook Usage=0.00%
Batch 626: Loss=99.0892, Perplexity=2.06, Codebook Usage=0.00%
Batch 627: Loss=101.9831, Perplexity=1.74, Codebook Usage=0.00%
Batch 628: Loss=93.1959, Perplexity=1.85, Codebook Usage=0.00%
Batch 629: Loss=141.2027, Perplexity=2.56, Codebook Usage=0.00%
Batch 630: Loss=92.7233, Perplexity=1.95, Codebook Usage=0.00%
Batch 631: Loss=97.5470, Perplexity=1.99, Codebook Usage=0.00%
Batch 632: Loss=84.0569, Perplexity=1.92, Codebook Usage=0.00%
Batch 633: Loss=100.6748, Perplexity=2.01, Codebook Usage=0.00%
Batch 634: Loss=82.1973, Perplexity=1.56, Codebook Usage=0.00%
Batch 635: Loss=110.8532, Perplexity=2.36, Codebook Usage=0.00%
Batch 636: Loss=116.5268, Perplexity=1.99, Codebook Usage=0.00%
Batch 637: Loss=79.4921, Perplexity=1.75, Codebook Usage=0.00%
Batch 638: Loss=84.6397, Perplexity=2.18, Codebook Usage=0.00%
Batch 639: Loss=76.5462, Perplexity=1.36, Codebook Usage=0.00%
Batch 640: Loss=119.7533, Perplexity=1.96, Codebook Usage=0.00%
Batch 641: Loss=127.7661, Perplexity=2.34, Codebook Usage=0.00%
Batch 642: Loss=125.0391, Perplexity=2.38, Codebook Usage=0.00%
Batch 643: Loss=97.9907, Perplexity=1.99, Codebook Usage=0.00%
Batch 644: Loss=95.2718, Perplexity=1.75, Codebook Usage=0.00%
Batch 645: Loss=124.1163, Perplexity=2.41, Codebook Usage=0.00%
Batch 646: Loss=69.6582, Perplexity=1.60, Codebook Usage=0.00%
Batch 647: Loss=97.3879, Perplexity=1.84, Codebook Usage=0.00%
Batch 648: Loss=109.4388, Perplexity=2.67, Codebook Usage=0.00%
Batch 649: Loss=90.9225, Perplexity=1.46, Codebook Usage=0.00%
Batch 650: Loss=79.4405, Perplexity=1.91, Codebook Usage=0.00%
Batch 651: Loss=87.4359, Perplexity=1.69, Codebook Usage=0.00%
Batch 652: Loss=93.6985, Perplexity=1.47, Codebook Usage=0.00%
Batch 653: Loss=115.4079, Perplexity=2.11, Codebook Usage=0.00%
Batch 654: Loss=116.2775, Perplexity=2.02, Codebook Usage=0.00%
Batch 655: Loss=108.5203, Perplexity=1.92, Codebook Usage=0.00%
Batch 656: Loss=90.7503, Perplexity=1.86, Codebook Usage=0.00%
Batch 657: Loss=90.8217, Perplexity=1.62, Codebook Usage=0.00%
Batch 658: Loss=114.5965, Perplexity=1.96, Codebook Usage=0.00%
Batch 659: Loss=100.5912, Perplexity=2.11, Codebook Usage=0.00%
Batch 660: Loss=116.9697, Perplexity=2.22, Codebook Usage=0.00%
Batch 661: Loss=76.4121, Perplexity=1.83, Codebook Usage=0.00%
Batch 662: Loss=88.8554, Perplexity=1.63, Codebook Usage=0.00%
Batch 663: Loss=119.7958, Perplexity=2.14, Codebook Usage=0.00%
Batch 664: Loss=78.8169, Perplexity=1.45, Codebook Usage=0.00%
Batch 665: Loss=96.9659, Perplexity=1.70, Codebook Usage=0.00%
Batch 666: Loss=70.8555, Perplexity=1.60, Codebook Usage=0.00%
Batch 667: Loss=86.9792, Perplexity=1.73, Codebook Usage=0.00%
Batch 668: Loss=121.5639, Perplexity=2.26, Codebook Usage=0.00%
Batch 669: Loss=93.5388, Perplexity=2.02, Codebook Usage=0.00%
Batch 670: Loss=92.9257, Perplexity=2.21, Codebook Usage=0.00%
Batch 671: Loss=117.3712, Perplexity=2.18, Codebook Usage=0.00%
Batch 672: Loss=93.1691, Perplexity=1.60, Codebook Usage=0.00%
Batch 673: Loss=83.2461, Perplexity=1.77, Codebook Usage=0.00%
Batch 674: Loss=92.9450, Perplexity=1.89, Codebook Usage=0.00%
Batch 675: Loss=88.5619, Perplexity=1.60, Codebook Usage=0.00%
Batch 676: Loss=68.1855, Perplexity=1.61, Codebook Usage=0.00%
Batch 677: Loss=98.2766, Perplexity=1.44, Codebook Usage=0.00%
Batch 678: Loss=77.1105, Perplexity=1.98, Codebook Usage=0.00%
Batch 679: Loss=106.4352, Perplexity=1.65, Codebook Usage=0.00%
Batch 680: Loss=82.1458, Perplexity=1.32, Codebook Usage=0.00%
Batch 681: Loss=101.2618, Perplexity=1.87, Codebook Usage=0.00%
Batch 682: Loss=99.7788, Perplexity=1.76, Codebook Usage=0.00%
Batch 683: Loss=105.2032, Perplexity=1.90, Codebook Usage=0.00%
Batch 684: Loss=106.7644, Perplexity=1.99, Codebook Usage=0.00%
Batch 685: Loss=100.5837, Perplexity=2.15, Codebook Usage=0.00%
Batch 686: Loss=87.3063, Perplexity=1.70, Codebook Usage=0.00%
Batch 687: Loss=68.1037, Perplexity=1.33, Codebook Usage=0.00%
Batch 688: Loss=123.7875, Perplexity=2.38, Codebook Usage=0.00%
Batch 689: Loss=105.1264, Perplexity=2.01, Codebook Usage=0.00%
Batch 690: Loss=104.4691, Perplexity=2.12, Codebook Usage=0.00%
Batch 691: Loss=64.2232, Perplexity=1.20, Codebook Usage=0.00%
Batch 692: Loss=88.7702, Perplexity=1.57, Codebook Usage=0.00%
Batch 693: Loss=111.3859, Perplexity=1.78, Codebook Usage=0.00%
Batch 694: Loss=75.5002, Perplexity=1.89, Codebook Usage=0.00%
Batch 695: Loss=121.1867, Perplexity=2.75, Codebook Usage=0.00%
Batch 696: Loss=103.3817, Perplexity=2.12, Codebook Usage=0.00%
Batch 697: Loss=111.9414, Perplexity=2.03, Codebook Usage=0.00%
Batch 698: Loss=70.4497, Perplexity=1.46, Codebook Usage=0.00%
Batch 699: Loss=94.7412, Perplexity=1.73, Codebook Usage=0.00%
Batch 700: Loss=109.4293, Perplexity=1.92, Codebook Usage=0.00%
Batch 701: Loss=105.6719, Perplexity=1.94, Codebook Usage=0.00%
Batch 702: Loss=66.2577, Perplexity=1.54, Codebook Usage=0.00%
Batch 703: Loss=98.7846, Perplexity=1.86, Codebook Usage=0.00%
Batch 704: Loss=137.7967, Perplexity=2.82, Codebook Usage=0.00%
Batch 705: Loss=99.5907, Perplexity=1.94, Codebook Usage=0.00%
Batch 706: Loss=92.1474, Perplexity=1.66, Codebook Usage=0.00%
Batch 707: Loss=79.9522, Perplexity=1.42, Codebook Usage=0.00%
Batch 708: Loss=79.9485, Perplexity=1.46, Codebook Usage=0.00%
Batch 709: Loss=81.2309, Perplexity=1.57, Codebook Usage=0.00%
Batch 710: Loss=90.5633, Perplexity=2.31, Codebook Usage=0.00%
Batch 711: Loss=132.2117, Perplexity=2.27, Codebook Usage=0.00%
Batch 712: Loss=93.6791, Perplexity=1.77, Codebook Usage=0.00%
Batch 713: Loss=96.5935, Perplexity=1.71, Codebook Usage=0.00%
Batch 714: Loss=89.3277, Perplexity=1.76, Codebook Usage=0.00%
Batch 715: Loss=116.8391, Perplexity=2.04, Codebook Usage=0.00%
Batch 716: Loss=110.9882, Perplexity=2.14, Codebook Usage=0.00%
Batch 717: Loss=108.4742, Perplexity=1.70, Codebook Usage=0.00%
Batch 718: Loss=74.5871, Perplexity=1.43, Codebook Usage=0.00%
Batch 719: Loss=100.4919, Perplexity=2.08, Codebook Usage=0.00%
Batch 720: Loss=84.3419, Perplexity=1.61, Codebook Usage=0.00%
Batch 721: Loss=99.0300, Perplexity=2.07, Codebook Usage=0.00%
Batch 722: Loss=97.8198, Perplexity=1.56, Codebook Usage=0.00%
Batch 723: Loss=119.5530, Perplexity=1.97, Codebook Usage=0.00%
Batch 724: Loss=85.0131, Perplexity=1.55, Codebook Usage=0.00%
Batch 725: Loss=63.7399, Perplexity=1.52, Codebook Usage=0.00%
Batch 726: Loss=101.1574, Perplexity=2.09, Codebook Usage=0.00%
Batch 727: Loss=70.0838, Perplexity=1.55, Codebook Usage=0.00%
Batch 728: Loss=94.2295, Perplexity=1.64, Codebook Usage=0.00%
Batch 729: Loss=97.9719, Perplexity=1.73, Codebook Usage=0.00%
Batch 730: Loss=104.2867, Perplexity=1.72, Codebook Usage=0.00%
Batch 731: Loss=115.0629, Perplexity=1.94, Codebook Usage=0.00%
Batch 732: Loss=127.3881, Perplexity=2.26, Codebook Usage=0.00%
Batch 733: Loss=133.7748, Perplexity=2.43, Codebook Usage=0.00%
Batch 734: Loss=60.5003, Perplexity=1.59, Codebook Usage=0.00%
Batch 735: Loss=79.1208, Perplexity=1.62, Codebook Usage=0.00%
Batch 736: Loss=102.8582, Perplexity=2.03, Codebook Usage=0.00%
Batch 737: Loss=77.8769, Perplexity=1.72, Codebook Usage=0.00%
Batch 738: Loss=96.3411, Perplexity=1.95, Codebook Usage=0.00%
Batch 739: Loss=98.4436, Perplexity=1.60, Codebook Usage=0.00%
Batch 740: Loss=58.1806, Perplexity=1.40, Codebook Usage=0.00%
Batch 741: Loss=88.9417, Perplexity=2.15, Codebook Usage=0.00%
Batch 742: Loss=113.3354, Perplexity=1.92, Codebook Usage=0.00%
Batch 743: Loss=101.0439, Perplexity=1.81, Codebook Usage=0.00%
Batch 744: Loss=85.7824, Perplexity=1.67, Codebook Usage=0.00%
Batch 745: Loss=98.4256, Perplexity=2.00, Codebook Usage=0.00%
Batch 746: Loss=84.8364, Perplexity=1.25, Codebook Usage=0.00%
Batch 747: Loss=109.5396, Perplexity=1.92, Codebook Usage=0.00%
Batch 748: Loss=87.3832, Perplexity=1.56, Codebook Usage=0.00%
Batch 749: Loss=98.3057, Perplexity=1.95, Codebook Usage=0.00%
Batch 750: Loss=115.0473, Perplexity=1.93, Codebook Usage=0.00%
Batch 751: Loss=122.4061, Perplexity=2.15, Codebook Usage=0.00%
Batch 752: Loss=87.4276, Perplexity=1.93, Codebook Usage=0.00%
Batch 753: Loss=104.0780, Perplexity=1.86, Codebook Usage=0.00%
Batch 754: Loss=92.4692, Perplexity=2.01, Codebook Usage=0.00%
Batch 755: Loss=110.5458, Perplexity=2.27, Codebook Usage=0.00%
Batch 756: Loss=106.7136, Perplexity=2.30, Codebook Usage=0.00%
Batch 757: Loss=89.1246, Perplexity=1.74, Codebook Usage=0.00%
Batch 758: Loss=134.1176, Perplexity=2.61, Codebook Usage=0.00%
Batch 759: Loss=121.8614, Perplexity=2.24, Codebook Usage=0.00%
Batch 760: Loss=92.4024, Perplexity=1.94, Codebook Usage=0.00%
Batch 761: Loss=132.6454, Perplexity=2.42, Codebook Usage=0.00%
Batch 762: Loss=102.4671, Perplexity=1.91, Codebook Usage=0.00%
Batch 763: Loss=106.3947, Perplexity=2.04, Codebook Usage=0.00%
Batch 764: Loss=72.5631, Perplexity=1.99, Codebook Usage=0.00%
Batch 765: Loss=59.4198, Perplexity=1.39, Codebook Usage=0.00%
Batch 766: Loss=105.9908, Perplexity=2.08, Codebook Usage=0.00%
Batch 767: Loss=104.2716, Perplexity=1.65, Codebook Usage=0.00%
Batch 768: Loss=118.0716, Perplexity=2.22, Codebook Usage=0.00%
Batch 769: Loss=113.5216, Perplexity=2.21, Codebook Usage=0.00%
Batch 770: Loss=99.9019, Perplexity=2.21, Codebook Usage=0.00%
Batch 771: Loss=113.7151, Perplexity=2.08, Codebook Usage=0.00%
Batch 772: Loss=105.3991, Perplexity=1.95, Codebook Usage=0.00%
Batch 773: Loss=74.3056, Perplexity=1.62, Codebook Usage=0.00%
Batch 774: Loss=76.3614, Perplexity=1.87, Codebook Usage=0.00%
Batch 775: Loss=87.6522, Perplexity=1.67, Codebook Usage=0.00%
Batch 776: Loss=108.7991, Perplexity=2.03, Codebook Usage=0.00%
Batch 777: Loss=100.5616, Perplexity=1.92, Codebook Usage=0.00%
Batch 778: Loss=65.0398, Perplexity=1.49, Codebook Usage=0.00%
Batch 779: Loss=96.9953, Perplexity=1.75, Codebook Usage=0.00%
Batch 780: Loss=96.0616, Perplexity=1.65, Codebook Usage=0.00%
Batch 781: Loss=104.6180, Perplexity=1.84, Codebook Usage=0.00%
Batch 782: Loss=106.5665, Perplexity=2.22, Codebook Usage=0.00%
Batch 783: Loss=122.4547, Perplexity=2.28, Codebook Usage=0.00%
Batch 784: Loss=92.5575, Perplexity=1.68, Codebook Usage=0.00%
Batch 785: Loss=109.7226, Perplexity=1.92, Codebook Usage=0.00%
Batch 786: Loss=60.8647, Perplexity=1.26, Codebook Usage=0.00%
Batch 787: Loss=125.9002, Perplexity=2.34, Codebook Usage=0.00%
Batch 788: Loss=130.2636, Perplexity=2.47, Codebook Usage=0.00%
Batch 789: Loss=105.3292, Perplexity=1.74, Codebook Usage=0.00%
Batch 790: Loss=82.5851, Perplexity=1.49, Codebook Usage=0.00%
Batch 791: Loss=113.3521, Perplexity=2.16, Codebook Usage=0.00%
Batch 792: Loss=104.9346, Perplexity=1.75, Codebook Usage=0.00%
Batch 793: Loss=65.6708, Perplexity=1.26, Codebook Usage=0.00%
Batch 794: Loss=97.5840, Perplexity=1.95, Codebook Usage=0.00%
Batch 795: Loss=66.4026, Perplexity=1.50, Codebook Usage=0.00%
Batch 796: Loss=102.2119, Perplexity=1.92, Codebook Usage=0.00%
Batch 797: Loss=86.4860, Perplexity=1.59, Codebook Usage=0.00%
Batch 798: Loss=88.7656, Perplexity=1.69, Codebook Usage=0.00%
Batch 799: Loss=100.6004, Perplexity=1.81, Codebook Usage=0.00%
Batch 800: Loss=94.5594, Perplexity=1.90, Codebook Usage=0.00%
Batch 801: Loss=100.2492, Perplexity=1.86, Codebook Usage=0.00%
Batch 802: Loss=90.2900, Perplexity=2.00, Codebook Usage=0.00%
Batch 803: Loss=98.4379, Perplexity=1.78, Codebook Usage=0.00%
Batch 804: Loss=80.6362, Perplexity=1.71, Codebook Usage=0.00%
Batch 805: Loss=110.4553, Perplexity=2.45, Codebook Usage=0.00%
Batch 806: Loss=102.1533, Perplexity=1.49, Codebook Usage=0.00%
Batch 807: Loss=93.6134, Perplexity=1.92, Codebook Usage=0.00%
Batch 808: Loss=74.4233, Perplexity=1.45, Codebook Usage=0.00%
Batch 809: Loss=96.2165, Perplexity=1.77, Codebook Usage=0.00%
Batch 810: Loss=85.0063, Perplexity=1.58, Codebook Usage=0.00%
Batch 811: Loss=71.4010, Perplexity=1.50, Codebook Usage=0.00%
Batch 812: Loss=141.1546, Perplexity=2.67, Codebook Usage=0.00%
Batch 813: Loss=82.0369, Perplexity=1.64, Codebook Usage=0.00%
Batch 814: Loss=100.3630, Perplexity=1.82, Codebook Usage=0.00%
Batch 815: Loss=96.2140, Perplexity=1.44, Codebook Usage=0.00%
Batch 816: Loss=92.1887, Perplexity=1.82, Codebook Usage=0.00%
Batch 817: Loss=63.9248, Perplexity=1.80, Codebook Usage=0.00%
Batch 818: Loss=73.6364, Perplexity=1.42, Codebook Usage=0.00%
Batch 819: Loss=91.1839, Perplexity=1.63, Codebook Usage=0.00%
Batch 820: Loss=124.5527, Perplexity=2.49, Codebook Usage=0.00%
Batch 821: Loss=134.8236, Perplexity=2.45, Codebook Usage=0.00%
Batch 822: Loss=111.5781, Perplexity=2.15, Codebook Usage=0.00%
Batch 823: Loss=79.6381, Perplexity=1.31, Codebook Usage=0.00%
Batch 824: Loss=105.0727, Perplexity=1.88, Codebook Usage=0.00%
Batch 825: Loss=120.9986, Perplexity=2.06, Codebook Usage=0.00%
Batch 826: Loss=109.8364, Perplexity=2.24, Codebook Usage=0.00%
Batch 827: Loss=78.0473, Perplexity=1.81, Codebook Usage=0.00%
Batch 828: Loss=106.5994, Perplexity=1.96, Codebook Usage=0.00%
Batch 829: Loss=101.0949, Perplexity=1.94, Codebook Usage=0.00%
Batch 830: Loss=112.7059, Perplexity=1.95, Codebook Usage=0.00%
Batch 831: Loss=99.1617, Perplexity=1.72, Codebook Usage=0.00%
Batch 832: Loss=70.9388, Perplexity=1.50, Codebook Usage=0.00%
Batch 833: Loss=98.0985, Perplexity=1.61, Codebook Usage=0.00%
Batch 834: Loss=72.6222, Perplexity=1.76, Codebook Usage=0.00%
Batch 835: Loss=118.5429, Perplexity=1.97, Codebook Usage=0.00%
Batch 836: Loss=123.1657, Perplexity=1.95, Codebook Usage=0.00%
Batch 837: Loss=162.0258, Perplexity=2.96, Codebook Usage=0.00%
Batch 838: Loss=88.4601, Perplexity=1.78, Codebook Usage=0.00%
Batch 839: Loss=114.9831, Perplexity=1.91, Codebook Usage=0.00%
Batch 840: Loss=78.5372, Perplexity=1.73, Codebook Usage=0.00%
Batch 841: Loss=127.1721, Perplexity=2.22, Codebook Usage=0.00%
Batch 842: Loss=123.1113, Perplexity=2.19, Codebook Usage=0.00%
Batch 843: Loss=79.4581, Perplexity=1.53, Codebook Usage=0.00%
Batch 844: Loss=114.0008, Perplexity=2.17, Codebook Usage=0.00%
Batch 845: Loss=85.5403, Perplexity=1.56, Codebook Usage=0.00%
Batch 846: Loss=69.2605, Perplexity=1.53, Codebook Usage=0.00%
Batch 847: Loss=111.3983, Perplexity=2.02, Codebook Usage=0.00%
Batch 848: Loss=107.7044, Perplexity=2.01, Codebook Usage=0.00%
Batch 849: Loss=88.2857, Perplexity=1.72, Codebook Usage=0.00%
Batch 850: Loss=99.6620, Perplexity=2.02, Codebook Usage=0.00%
Batch 851: Loss=117.1121, Perplexity=2.28, Codebook Usage=0.00%
Batch 852: Loss=110.5992, Perplexity=1.88, Codebook Usage=0.00%
Batch 853: Loss=71.3362, Perplexity=1.58, Codebook Usage=0.00%
Batch 854: Loss=83.1045, Perplexity=1.62, Codebook Usage=0.00%
Batch 855: Loss=117.8493, Perplexity=2.06, Codebook Usage=0.00%
Batch 856: Loss=114.9304, Perplexity=2.32, Codebook Usage=0.00%
Batch 857: Loss=68.7814, Perplexity=1.52, Codebook Usage=0.00%
Batch 858: Loss=83.3957, Perplexity=1.56, Codebook Usage=0.00%
Batch 859: Loss=90.9215, Perplexity=2.22, Codebook Usage=0.00%
Batch 860: Loss=82.2114, Perplexity=1.66, Codebook Usage=0.00%
Batch 861: Loss=104.2671, Perplexity=2.14, Codebook Usage=0.00%
Batch 862: Loss=118.4709, Perplexity=2.15, Codebook Usage=0.00%
Batch 863: Loss=89.2683, Perplexity=1.21, Codebook Usage=0.00%
Batch 864: Loss=94.9559, Perplexity=1.91, Codebook Usage=0.00%
Batch 865: Loss=86.9245, Perplexity=1.75, Codebook Usage=0.00%
Batch 866: Loss=94.2770, Perplexity=1.17, Codebook Usage=0.00%
Batch 867: Loss=107.3577, Perplexity=2.25, Codebook Usage=0.00%
Batch 868: Loss=102.5166, Perplexity=2.09, Codebook Usage=0.00%
Batch 869: Loss=111.5871, Perplexity=2.08, Codebook Usage=0.00%
Batch 870: Loss=93.5749, Perplexity=1.89, Codebook Usage=0.00%
Batch 871: Loss=119.2850, Perplexity=1.96, Codebook Usage=0.00%
Batch 872: Loss=98.3073, Perplexity=1.88, Codebook Usage=0.00%
Batch 873: Loss=108.5602, Perplexity=1.76, Codebook Usage=0.00%
Batch 874: Loss=79.9339, Perplexity=1.45, Codebook Usage=0.00%
Batch 875: Loss=80.0486, Perplexity=1.84, Codebook Usage=0.00%
Batch 876: Loss=59.3759, Perplexity=1.26, Codebook Usage=0.00%
Batch 877: Loss=93.8295, Perplexity=1.50, Codebook Usage=0.00%
Batch 878: Loss=86.9447, Perplexity=1.60, Codebook Usage=0.00%
Batch 879: Loss=116.0552, Perplexity=2.39, Codebook Usage=0.00%
Batch 880: Loss=83.2944, Perplexity=1.53, Codebook Usage=0.00%
Batch 881: Loss=100.4150, Perplexity=1.69, Codebook Usage=0.00%
Batch 882: Loss=74.9834, Perplexity=1.79, Codebook Usage=0.00%
Batch 883: Loss=73.5032, Perplexity=1.45, Codebook Usage=0.00%
Batch 884: Loss=81.3729, Perplexity=1.89, Codebook Usage=0.00%
Batch 885: Loss=90.2408, Perplexity=1.98, Codebook Usage=0.00%
Batch 886: Loss=82.6235, Perplexity=1.80, Codebook Usage=0.00%
Batch 887: Loss=97.3340, Perplexity=2.15, Codebook Usage=0.00%
Batch 888: Loss=95.9368, Perplexity=1.55, Codebook Usage=0.00%
Batch 889: Loss=100.8992, Perplexity=1.95, Codebook Usage=0.00%
Batch 890: Loss=82.9934, Perplexity=1.78, Codebook Usage=0.00%
Batch 891: Loss=97.8240, Perplexity=1.90, Codebook Usage=0.00%
Batch 892: Loss=114.4526, Perplexity=2.12, Codebook Usage=0.00%
Batch 893: Loss=111.1928, Perplexity=2.11, Codebook Usage=0.00%
Batch 894: Loss=110.1153, Perplexity=2.38, Codebook Usage=0.00%
Batch 895: Loss=102.7354, Perplexity=1.90, Codebook Usage=0.00%
Batch 896: Loss=93.5996, Perplexity=1.57, Codebook Usage=0.00%
Batch 897: Loss=93.9168, Perplexity=1.68, Codebook Usage=0.00%
Batch 898: Loss=119.7318, Perplexity=2.02, Codebook Usage=0.00%
Batch 899: Loss=79.8860, Perplexity=1.80, Codebook Usage=0.00%
Batch 900: Loss=71.9794, Perplexity=1.60, Codebook Usage=0.00%
Batch 901: Loss=111.3536, Perplexity=2.28, Codebook Usage=0.00%
Batch 902: Loss=113.0804, Perplexity=2.03, Codebook Usage=0.00%
Batch 903: Loss=122.8119, Perplexity=2.32, Codebook Usage=0.00%
Batch 904: Loss=97.3159, Perplexity=1.99, Codebook Usage=0.00%
Batch 905: Loss=101.7843, Perplexity=2.10, Codebook Usage=0.00%
Batch 906: Loss=121.6525, Perplexity=2.30, Codebook Usage=0.00%
Batch 907: Loss=86.1811, Perplexity=1.82, Codebook Usage=0.00%
Batch 908: Loss=67.2626, Perplexity=1.58, Codebook Usage=0.00%
Batch 909: Loss=75.3900, Perplexity=1.75, Codebook Usage=0.00%
Batch 910: Loss=94.3866, Perplexity=1.60, Codebook Usage=0.00%
Batch 911: Loss=101.1678, Perplexity=2.12, Codebook Usage=0.00%
Batch 912: Loss=89.2243, Perplexity=1.85, Codebook Usage=0.00%
Batch 913: Loss=112.4096, Perplexity=2.08, Codebook Usage=0.00%
Batch 914: Loss=107.8434, Perplexity=2.14, Codebook Usage=0.00%
Batch 915: Loss=101.4346, Perplexity=2.17, Codebook Usage=0.00%
Batch 916: Loss=95.7968, Perplexity=2.23, Codebook Usage=0.00%
Batch 917: Loss=74.2884, Perplexity=1.41, Codebook Usage=0.00%
Batch 918: Loss=54.7635, Perplexity=1.55, Codebook Usage=0.00%
Batch 919: Loss=77.9722, Perplexity=1.62, Codebook Usage=0.00%
Batch 920: Loss=93.4020, Perplexity=2.06, Codebook Usage=0.00%
Batch 921: Loss=79.1449, Perplexity=1.39, Codebook Usage=0.00%
Batch 922: Loss=105.3649, Perplexity=2.27, Codebook Usage=0.00%
Batch 923: Loss=65.3491, Perplexity=1.64, Codebook Usage=0.00%
Batch 924: Loss=129.4817, Perplexity=2.30, Codebook Usage=0.00%
Batch 925: Loss=125.6963, Perplexity=2.10, Codebook Usage=0.00%
Batch 926: Loss=77.3182, Perplexity=1.62, Codebook Usage=0.00%
Batch 927: Loss=73.3817, Perplexity=1.64, Codebook Usage=0.00%
Batch 928: Loss=121.7478, Perplexity=2.02, Codebook Usage=0.00%
Batch 929: Loss=82.1447, Perplexity=2.07, Codebook Usage=0.00%
Batch 930: Loss=95.5274, Perplexity=1.81, Codebook Usage=0.00%
Batch 931: Loss=74.2171, Perplexity=1.39, Codebook Usage=0.00%
Batch 932: Loss=107.1194, Perplexity=2.05, Codebook Usage=0.00%
Batch 933: Loss=66.9138, Perplexity=1.51, Codebook Usage=0.00%
Batch 934: Loss=107.0040, Perplexity=2.19, Codebook Usage=0.00%
Batch 935: Loss=96.8939, Perplexity=1.64, Codebook Usage=0.00%
Batch 936: Loss=93.5061, Perplexity=1.87, Codebook Usage=0.00%
Batch 937: Loss=76.6898, Perplexity=1.48, Codebook Usage=0.00%
Batch 938: Loss=88.1632, Perplexity=1.41, Codebook Usage=0.00%
Batch 939: Loss=103.7874, Perplexity=1.88, Codebook Usage=0.00%
Batch 940: Loss=86.8359, Perplexity=1.65, Codebook Usage=0.00%
Batch 941: Loss=80.8751, Perplexity=1.63, Codebook Usage=0.00%
Batch 942: Loss=96.9369, Perplexity=1.56, Codebook Usage=0.00%
Batch 943: Loss=123.9288, Perplexity=2.01, Codebook Usage=0.00%
Batch 944: Loss=124.6872, Perplexity=2.04, Codebook Usage=0.00%
Batch 945: Loss=95.8040, Perplexity=1.59, Codebook Usage=0.00%
Batch 946: Loss=106.1822, Perplexity=2.06, Codebook Usage=0.00%
Batch 947: Loss=86.8605, Perplexity=1.46, Codebook Usage=0.00%
Batch 948: Loss=78.5283, Perplexity=1.34, Codebook Usage=0.00%
Batch 949: Loss=79.2755, Perplexity=1.92, Codebook Usage=0.00%
Batch 950: Loss=91.5364, Perplexity=1.45, Codebook Usage=0.00%
Batch 951: Loss=94.7957, Perplexity=2.30, Codebook Usage=0.00%
Batch 952: Loss=117.9238, Perplexity=2.07, Codebook Usage=0.00%
Batch 953: Loss=112.7797, Perplexity=2.00, Codebook Usage=0.00%
Batch 954: Loss=105.6508, Perplexity=2.09, Codebook Usage=0.00%
Batch 955: Loss=96.6695, Perplexity=2.25, Codebook Usage=0.00%
Batch 956: Loss=101.7811, Perplexity=2.00, Codebook Usage=0.00%
Batch 957: Loss=102.3256, Perplexity=1.75, Codebook Usage=0.00%
Batch 958: Loss=101.3253, Perplexity=2.21, Codebook Usage=0.00%
Batch 959: Loss=93.7244, Perplexity=1.87, Codebook Usage=0.00%
Batch 960: Loss=74.4118, Perplexity=1.31, Codebook Usage=0.00%
Batch 961: Loss=101.9641, Perplexity=1.75, Codebook Usage=0.00%
Batch 962: Loss=99.5043, Perplexity=1.72, Codebook Usage=0.00%
Batch 963: Loss=104.6405, Perplexity=2.24, Codebook Usage=0.00%
Batch 964: Loss=91.7802, Perplexity=1.80, Codebook Usage=0.00%
Batch 965: Loss=99.4951, Perplexity=1.91, Codebook Usage=0.00%
Batch 966: Loss=103.3486, Perplexity=1.85, Codebook Usage=0.00%
Batch 967: Loss=84.9812, Perplexity=2.05, Codebook Usage=0.00%
Batch 968: Loss=75.9398, Perplexity=1.73, Codebook Usage=0.00%
Batch 969: Loss=70.3955, Perplexity=1.56, Codebook Usage=0.00%
Batch 970: Loss=95.4610, Perplexity=1.88, Codebook Usage=0.00%
Batch 971: Loss=93.1163, Perplexity=1.94, Codebook Usage=0.00%
Batch 972: Loss=93.3857, Perplexity=1.80, Codebook Usage=0.00%
Batch 973: Loss=106.5111, Perplexity=1.83, Codebook Usage=0.00%
Batch 974: Loss=98.5135, Perplexity=1.82, Codebook Usage=0.00%
Batch 975: Loss=113.8102, Perplexity=1.92, Codebook Usage=0.00%
Batch 976: Loss=54.5869, Perplexity=1.50, Codebook Usage=0.00%
Batch 977: Loss=115.0802, Perplexity=2.04, Codebook Usage=0.00%
Batch 978: Loss=78.1966, Perplexity=1.21, Codebook Usage=0.00%
Batch 979: Loss=118.3814, Perplexity=1.96, Codebook Usage=0.00%
Batch 980: Loss=87.2292, Perplexity=2.08, Codebook Usage=0.00%
Batch 981: Loss=87.1075, Perplexity=1.72, Codebook Usage=0.00%
Batch 982: Loss=110.9400, Perplexity=2.30, Codebook Usage=0.00%
Batch 983: Loss=107.8355, Perplexity=2.13, Codebook Usage=0.00%
Batch 984: Loss=101.8329, Perplexity=1.49, Codebook Usage=0.00%
Batch 985: Loss=110.2511, Perplexity=2.06, Codebook Usage=0.00%
Batch 986: Loss=121.7924, Perplexity=2.02, Codebook Usage=0.00%
Batch 987: Loss=73.6578, Perplexity=1.74, Codebook Usage=0.00%
Batch 988: Loss=94.9901, Perplexity=1.83, Codebook Usage=0.00%
Batch 989: Loss=92.2094, Perplexity=1.76, Codebook Usage=0.00%
Batch 990: Loss=102.9024, Perplexity=1.77, Codebook Usage=0.00%
Batch 991: Loss=86.6142, Perplexity=1.58, Codebook Usage=0.00%
Batch 992: Loss=83.8063, Perplexity=1.79, Codebook Usage=0.00%
Batch 993: Loss=103.0619, Perplexity=1.99, Codebook Usage=0.00%
Batch 994: Loss=79.6776, Perplexity=1.53, Codebook Usage=0.00%
Batch 995: Loss=108.5973, Perplexity=2.26, Codebook Usage=0.00%
Batch 996: Loss=108.9128, Perplexity=2.19, Codebook Usage=0.00%
Batch 997: Loss=107.3008, Perplexity=1.69, Codebook Usage=0.00%
Batch 998: Loss=101.7163, Perplexity=2.13, Codebook Usage=0.00%
Batch 999: Loss=114.7996, Perplexity=2.06, Codebook Usage=0.00%
Batch 1000: Loss=75.9130, Perplexity=1.60, Codebook Usage=0.00%
Batch 1001: Loss=85.2055, Perplexity=1.66, Codebook Usage=0.00%
Batch 1002: Loss=107.8895, Perplexity=1.90, Codebook Usage=0.00%
Batch 1003: Loss=86.0704, Perplexity=2.05, Codebook Usage=0.00%
Batch 1004: Loss=99.4124, Perplexity=1.85, Codebook Usage=0.00%
Batch 1005: Loss=104.1148, Perplexity=1.98, Codebook Usage=0.00%
Batch 1006: Loss=83.5723, Perplexity=1.59, Codebook Usage=0.00%
Batch 1007: Loss=83.3024, Perplexity=1.81, Codebook Usage=0.00%
Batch 1008: Loss=77.2749, Perplexity=1.64, Codebook Usage=0.00%
Batch 1009: Loss=99.5010, Perplexity=1.98, Codebook Usage=0.00%
Batch 1010: Loss=62.9986, Perplexity=1.57, Codebook Usage=0.00%
Batch 1011: Loss=78.5180, Perplexity=1.41, Codebook Usage=0.00%
Batch 1012: Loss=96.9683, Perplexity=1.84, Codebook Usage=0.00%
Batch 1013: Loss=86.7754, Perplexity=1.49, Codebook Usage=0.00%
Batch 1014: Loss=50.7588, Perplexity=1.37, Codebook Usage=0.00%
Batch 1015: Loss=127.3152, Perplexity=1.94, Codebook Usage=0.00%
Batch 1016: Loss=88.4329, Perplexity=1.51, Codebook Usage=0.00%
Batch 1017: Loss=79.4661, Perplexity=1.53, Codebook Usage=0.00%
Batch 1018: Loss=83.4890, Perplexity=1.87, Codebook Usage=0.00%
Batch 1019: Loss=78.2787, Perplexity=1.59, Codebook Usage=0.00%
Batch 1020: Loss=98.9623, Perplexity=1.91, Codebook Usage=0.00%
Batch 1021: Loss=105.0094, Perplexity=1.81, Codebook Usage=0.00%
Batch 1022: Loss=99.9945, Perplexity=1.86, Codebook Usage=0.00%
Batch 1023: Loss=97.3618, Perplexity=2.12, Codebook Usage=0.00%
Batch 1024: Loss=95.0733, Perplexity=2.05, Codebook Usage=0.00%
Batch 1025: Loss=102.1844, Perplexity=2.28, Codebook Usage=0.00%
Batch 1026: Loss=72.6282, Perplexity=1.81, Codebook Usage=0.00%
Batch 1027: Loss=80.5100, Perplexity=1.85, Codebook Usage=0.00%
Batch 1028: Loss=126.2342, Perplexity=2.29, Codebook Usage=0.00%
Batch 1029: Loss=88.3892, Perplexity=1.92, Codebook Usage=0.00%
Batch 1030: Loss=90.8186, Perplexity=2.08, Codebook Usage=0.00%
Batch 1031: Loss=81.7275, Perplexity=1.50, Codebook Usage=0.00%
Batch 1032: Loss=111.5514, Perplexity=1.98, Codebook Usage=0.00%
Batch 1033: Loss=101.9346, Perplexity=2.18, Codebook Usage=0.00%
Batch 1034: Loss=93.5289, Perplexity=1.68, Codebook Usage=0.00%
Batch 1035: Loss=124.4185, Perplexity=2.26, Codebook Usage=0.00%
Batch 1036: Loss=89.7255, Perplexity=1.84, Codebook Usage=0.00%
Batch 1037: Loss=74.8868, Perplexity=1.98, Codebook Usage=0.00%
Batch 1038: Loss=103.9415, Perplexity=2.14, Codebook Usage=0.00%
Batch 1039: Loss=94.9814, Perplexity=1.89, Codebook Usage=0.00%
Batch 1040: Loss=116.1800, Perplexity=2.07, Codebook Usage=0.00%
Batch 1041: Loss=113.4993, Perplexity=2.13, Codebook Usage=0.00%
Batch 1042: Loss=142.5935, Perplexity=2.67, Codebook Usage=0.00%
Batch 1043: Loss=93.6752, Perplexity=1.92, Codebook Usage=0.00%
Batch 1044: Loss=119.1014, Perplexity=2.10, Codebook Usage=0.00%
Batch 1045: Loss=97.2073, Perplexity=1.75, Codebook Usage=0.00%
Batch 1046: Loss=70.2217, Perplexity=1.90, Codebook Usage=0.00%
Batch 1047: Loss=115.0263, Perplexity=2.19, Codebook Usage=0.00%
Batch 1048: Loss=114.6960, Perplexity=1.81, Codebook Usage=0.00%
Batch 1049: Loss=105.4370, Perplexity=1.94, Codebook Usage=0.00%
Batch 1050: Loss=97.5371, Perplexity=2.06, Codebook Usage=0.00%
Batch 1051: Loss=61.4496, Perplexity=1.26, Codebook Usage=0.00%
Batch 1052: Loss=100.5247, Perplexity=1.57, Codebook Usage=0.00%
Batch 1053: Loss=95.6374, Perplexity=1.86, Codebook Usage=0.00%
Batch 1054: Loss=80.3929, Perplexity=1.77, Codebook Usage=0.00%
Batch 1055: Loss=124.1860, Perplexity=2.21, Codebook Usage=0.00%
Batch 1056: Loss=116.7443, Perplexity=2.47, Codebook Usage=0.00%
Batch 1057: Loss=89.9330, Perplexity=1.83, Codebook Usage=0.00%
Batch 1058: Loss=92.8750, Perplexity=1.74, Codebook Usage=0.00%
Batch 1059: Loss=92.2773, Perplexity=1.75, Codebook Usage=0.00%
Batch 1060: Loss=104.7010, Perplexity=1.86, Codebook Usage=0.00%
Batch 1061: Loss=97.9577, Perplexity=1.66, Codebook Usage=0.00%
Batch 1062: Loss=127.7550, Perplexity=2.59, Codebook Usage=0.00%
Batch 1063: Loss=79.1966, Perplexity=1.77, Codebook Usage=0.00%
Batch 1064: Loss=96.7520, Perplexity=1.51, Codebook Usage=0.00%
Batch 1065: Loss=76.4114, Perplexity=1.50, Codebook Usage=0.00%
Batch 1066: Loss=123.7862, Perplexity=2.53, Codebook Usage=0.00%
Batch 1067: Loss=74.8792, Perplexity=1.66, Codebook Usage=0.00%
Batch 1068: Loss=86.6543, Perplexity=1.49, Codebook Usage=0.00%
Batch 1069: Loss=124.7046, Perplexity=2.04, Codebook Usage=0.00%
Batch 1070: Loss=62.6761, Perplexity=1.47, Codebook Usage=0.00%
Batch 1071: Loss=106.5468, Perplexity=1.86, Codebook Usage=0.00%
Batch 1072: Loss=95.0543, Perplexity=1.70, Codebook Usage=0.00%
Batch 1073: Loss=75.1995, Perplexity=1.54, Codebook Usage=0.00%
Batch 1074: Loss=108.3186, Perplexity=1.88, Codebook Usage=0.00%
Batch 1075: Loss=112.1044, Perplexity=1.88, Codebook Usage=0.00%
Batch 1076: Loss=97.4852, Perplexity=1.74, Codebook Usage=0.00%
Batch 1077: Loss=116.2870, Perplexity=1.93, Codebook Usage=0.00%
Batch 1078: Loss=72.2864, Perplexity=1.76, Codebook Usage=0.00%
Batch 1079: Loss=106.5880, Perplexity=2.25, Codebook Usage=0.00%
Batch 1080: Loss=104.5597, Perplexity=1.87, Codebook Usage=0.00%
Batch 1081: Loss=103.1958, Perplexity=1.77, Codebook Usage=0.00%
Batch 1082: Loss=94.2832, Perplexity=1.55, Codebook Usage=0.00%
Batch 1083: Loss=105.0401, Perplexity=1.83, Codebook Usage=0.00%
Batch 1084: Loss=96.9336, Perplexity=2.03, Codebook Usage=0.00%
Batch 1085: Loss=80.9674, Perplexity=1.80, Codebook Usage=0.00%
Batch 1086: Loss=120.1180, Perplexity=2.37, Codebook Usage=0.00%
Batch 1087: Loss=99.9409, Perplexity=1.83, Codebook Usage=0.00%
Batch 1088: Loss=93.6486, Perplexity=1.59, Codebook Usage=0.00%
Batch 1089: Loss=99.2900, Perplexity=1.87, Codebook Usage=0.00%
Batch 1090: Loss=132.9498, Perplexity=2.64, Codebook Usage=0.00%
Batch 1091: Loss=84.2593, Perplexity=1.81, Codebook Usage=0.00%
Batch 1092: Loss=89.1162, Perplexity=1.65, Codebook Usage=0.00%
Batch 1093: Loss=140.6084, Perplexity=2.50, Codebook Usage=0.00%
Batch 1094: Loss=104.5862, Perplexity=2.13, Codebook Usage=0.00%
Batch 1095: Loss=99.1992, Perplexity=1.67, Codebook Usage=0.00%
Batch 1096: Loss=106.3210, Perplexity=2.07, Codebook Usage=0.00%
Batch 1097: Loss=94.2848, Perplexity=1.54, Codebook Usage=0.00%
Batch 1098: Loss=89.0674, Perplexity=1.80, Codebook Usage=0.00%
Batch 1099: Loss=91.7574, Perplexity=1.63, Codebook Usage=0.00%
Batch 1100: Loss=70.5488, Perplexity=1.29, Codebook Usage=0.00%
Batch 1101: Loss=90.0760, Perplexity=1.95, Codebook Usage=0.00%
Batch 1102: Loss=116.0826, Perplexity=2.03, Codebook Usage=0.00%
Batch 1103: Loss=92.0735, Perplexity=1.92, Codebook Usage=0.00%
Batch 1104: Loss=101.6525, Perplexity=1.69, Codebook Usage=0.00%
Batch 1105: Loss=100.3198, Perplexity=2.15, Codebook Usage=0.00%
Batch 1106: Loss=123.4487, Perplexity=2.52, Codebook Usage=0.00%
Batch 1107: Loss=62.3849, Perplexity=1.15, Codebook Usage=0.00%
Batch 1108: Loss=84.0248, Perplexity=1.73, Codebook Usage=0.00%
Batch 1109: Loss=102.2516, Perplexity=1.97, Codebook Usage=0.00%
Batch 1110: Loss=60.9055, Perplexity=1.35, Codebook Usage=0.00%
Batch 1111: Loss=67.1396, Perplexity=1.34, Codebook Usage=0.00%
Batch 1112: Loss=90.3454, Perplexity=2.16, Codebook Usage=0.00%
Batch 1113: Loss=100.5453, Perplexity=2.06, Codebook Usage=0.00%
Batch 1114: Loss=72.5633, Perplexity=1.65, Codebook Usage=0.00%
Batch 1115: Loss=108.4893, Perplexity=2.03, Codebook Usage=0.00%
Batch 1116: Loss=86.0086, Perplexity=1.81, Codebook Usage=0.00%
Batch 1117: Loss=91.7857, Perplexity=1.67, Codebook Usage=0.00%
Batch 1118: Loss=103.9416, Perplexity=1.61, Codebook Usage=0.00%
Batch 1119: Loss=95.3340, Perplexity=1.97, Codebook Usage=0.00%
Batch 1120: Loss=86.0696, Perplexity=1.57, Codebook Usage=0.00%
Batch 1121: Loss=87.8599, Perplexity=1.80, Codebook Usage=0.00%
Batch 1122: Loss=108.9668, Perplexity=2.20, Codebook Usage=0.00%
Batch 1123: Loss=70.6529, Perplexity=1.50, Codebook Usage=0.00%
Batch 1124: Loss=99.1169, Perplexity=2.04, Codebook Usage=0.00%
Batch 1125: Loss=116.6832, Perplexity=1.86, Codebook Usage=0.00%
Batch 1126: Loss=109.2973, Perplexity=1.99, Codebook Usage=0.00%
Batch 1127: Loss=112.5237, Perplexity=1.77, Codebook Usage=0.00%
Batch 1128: Loss=115.3878, Perplexity=1.86, Codebook Usage=0.00%
Batch 1129: Loss=85.9647, Perplexity=1.39, Codebook Usage=0.00%
Batch 1130: Loss=119.2043, Perplexity=2.47, Codebook Usage=0.00%
Batch 1131: Loss=101.8799, Perplexity=1.92, Codebook Usage=0.00%
Batch 1132: Loss=99.2724, Perplexity=1.66, Codebook Usage=0.00%
Batch 1133: Loss=109.4196, Perplexity=1.96, Codebook Usage=0.00%
Batch 1134: Loss=72.8451, Perplexity=2.08, Codebook Usage=0.00%
Batch 1135: Loss=83.3027, Perplexity=1.64, Codebook Usage=0.00%
Batch 1136: Loss=100.3954, Perplexity=1.82, Codebook Usage=0.00%
Batch 1137: Loss=60.5328, Perplexity=1.29, Codebook Usage=0.00%
Batch 1138: Loss=122.6717, Perplexity=2.16, Codebook Usage=0.00%
Batch 1139: Loss=74.4341, Perplexity=1.67, Codebook Usage=0.00%
Batch 1140: Loss=91.4570, Perplexity=1.79, Codebook Usage=0.00%
Batch 1141: Loss=106.2358, Perplexity=2.02, Codebook Usage=0.00%
Batch 1142: Loss=95.6215, Perplexity=1.80, Codebook Usage=0.00%
Batch 1143: Loss=96.0214, Perplexity=1.85, Codebook Usage=0.00%
Batch 1144: Loss=92.3370, Perplexity=1.58, Codebook Usage=0.00%
Batch 1145: Loss=78.2471, Perplexity=1.86, Codebook Usage=0.00%
Batch 1146: Loss=108.4174, Perplexity=1.80, Codebook Usage=0.00%
Batch 1147: Loss=96.2222, Perplexity=1.83, Codebook Usage=0.00%
Batch 1148: Loss=128.4919, Perplexity=2.28, Codebook Usage=0.00%
Batch 1149: Loss=89.6440, Perplexity=1.64, Codebook Usage=0.00%
Batch 1150: Loss=136.1199, Perplexity=2.60, Codebook Usage=0.00%
Batch 1151: Loss=88.1031, Perplexity=1.51, Codebook Usage=0.00%
Batch 1152: Loss=109.9686, Perplexity=2.23, Codebook Usage=0.00%
Batch 1153: Loss=72.3155, Perplexity=1.76, Codebook Usage=0.00%
Batch 1154: Loss=81.2863, Perplexity=1.35, Codebook Usage=0.00%
Batch 1155: Loss=90.9147, Perplexity=1.68, Codebook Usage=0.00%
Batch 1156: Loss=81.1546, Perplexity=1.85, Codebook Usage=0.00%
Batch 1157: Loss=96.5293, Perplexity=1.75, Codebook Usage=0.00%
Batch 1158: Loss=111.2231, Perplexity=1.81, Codebook Usage=0.00%
Batch 1159: Loss=111.8471, Perplexity=2.00, Codebook Usage=0.00%
Batch 1160: Loss=117.8759, Perplexity=2.05, Codebook Usage=0.00%
Batch 1161: Loss=79.0063, Perplexity=1.74, Codebook Usage=0.00%
Batch 1162: Loss=101.2370, Perplexity=1.68, Codebook Usage=0.00%
Batch 1163: Loss=77.6303, Perplexity=1.64, Codebook Usage=0.00%
Batch 1164: Loss=100.6923, Perplexity=2.07, Codebook Usage=0.00%
Batch 1165: Loss=102.8757, Perplexity=2.04, Codebook Usage=0.00%
Batch 1166: Loss=106.9496, Perplexity=1.84, Codebook Usage=0.00%
Batch 1167: Loss=105.9904, Perplexity=1.83, Codebook Usage=0.00%
Batch 1168: Loss=74.0551, Perplexity=1.70, Codebook Usage=0.00%
Batch 1169: Loss=91.9841, Perplexity=1.66, Codebook Usage=0.00%
